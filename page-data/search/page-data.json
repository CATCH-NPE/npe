{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"서론 지금까지 가상 메모리를 통해서 실제 물리적 메모리 보다 더 많은 프로세스를 실행할 수 있다고 배웠습니다.\n이러한 행위는 한정된 메모리를 어떻게 더 효율적으로 사용할까에서 출발하게 됩니다. 그럼에도 더 효율적인 메모리를 이용하기 위해서 두가지 방법을 더 고려하게 됩니다. 불필요한 페이지를 선별 후 스왑 아웃 한다. 프로세스에게 적절한 프레임을 할당한다…","fields":{"slug":"/23/"},"frontmatter":{"date":"September 26, 2025","title":"요구페이징을 잘 수행하기 위해서 필요한 것들","tags":["운영체제"]},"rawMarkdownBody":"\n## 서론\n\n---\n\n지금까지 **가상 메모리**를 통해서 실제 물리적 메모리 보다 더 많은 프로세스를 실행할 수 있다고 배웠습니다.\n이러한 행위는 한정된 **메모리**를 어떻게 더 효율적으로 사용할까에서 출발하게 됩니다.\n\n그럼에도 더 효율적인 메모리를 이용하기 위해서 두가지 방법을 더 고려하게 됩니다.\n\n1. 불필요한 페이지를 **선별** 후 **스왑 아웃** 한다.\n2. 프로세스에게 적절한 **프레임**을 할당한다.\n\n각각 **페이지 교체 알고리즘**, **프레임 할당**이라고 부릅니다.\n\n또한, 이러한 작업은 **요구 페이징(demand paging)** 이라는 작업을 더 효율적으로 할 수 있게 돕습니다.\n\n이 글은 요구 페이징에 대해서 알아보고, 요구 페이징이 안정적으로 작동하기 위해 필연적인 페이지 교체 알고리즘과, 프레임 할당을 설명합니다.\n\n<br>\n<br>\n\n## 요구 페이징(demand paging)\n\n---\n\n프로세스를 메모리에 적재할 떄 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 방식을\n**요구 페이징**이라고 부릅니다.\n\n요구 페이징은 다음과 같은 플로우로 진행됩니다.\n\n1. CPU가 특정 페이지에 접근하는 명령어를 내린다.\n2. 페이지가 메모리에 존재하면 **유효비트 1**을 나타내며 해당 프레임에 접근한다.\n3. 존재 하지 않는다면 **유효비트 0**을 나타내며 **페이지 폴트**가 발생한다.\n4. **페이지 폴트**가 발생하면 해당 페이지를 메모리로 적재하고 유효비트를 1로 설정한다.\n5. 1번을 다시 시행한다.\n\n이러한 **요구 페이징**은 필요한 페이지만 그때그때 불러서 적재 후 사용한다는 의미를 나타냅니다.\n\n**요구 페이징**을 안정적으로 수행하기 위해서는 크게 두가지를 고려해야 합니다.\n첫번째는, **요구 페이징**은 메모리 기준 **Input**작업 입니다.\n그렇다면 반대로 **Output**작업도 필요하게 됩니다.\n\n왜냐하면 메모리는 한정되고 상대적으로 덜 필요한 페이지를 **스왑아웃**하는 작업도 필요하기 때문입니다.\n\n이러한 방식을 **페이지 교체** 라고 부르며, 그중 여러가지 방식이 있기 때문에 **페이지 교체 알고리즘**으로 분류하고 명명합니다.\n\n두번째는, 한정된 프레임을 잘 배분하는 것으로 **스왑 아웃**자체를 줄일 수 있기 때문에 **프레임 할당** 또한\n**요구 페이징**을 수행하기 위해 중요합니다.\n\n<br>\n<br>\n\n# 페이지 교체 알고리즘\n\n---\n\n페이지 교체 알고리즘은 **스왑 아웃**할 페이지를 **선별**하는 알고리즘입니다.\n그렇기 때문에 어떤 **선별 기준**에 따라 알고리즘을 나누게 됩니다.\n\n일반적으로 **기준**은 **페이지 폴트** 발생 비율입니다. **페이지 폴트**는 보조기억장치로 부터\n정보를 가져와서 메모리로 할당하여 그 정보를 불러와야 하는 비효율적인 시퀀스를 가지고 있습니다.\n이러한 **페이지 폴트** 발생 비율이 적은 교체 알고리즘을 좋다고 평가합니다.\n\n그리고 **페이지 폴트 횟수**는 **페이지 참조열**을 통해서 진행합니다.\n\n가령,\n\n> 2 2 2 3 5 5 5 3 3 7\n\n이라는 페이지 참조가 발생한다면 **페이지 참조열**은 여기서 연속된 중복을 제거한 순서입니다.\n\n> 2 3 5 3 7\n\n이 해당 순서에 **페이지 참조열**이 됩니다. 이렇게 중복을 제거하는 이유는 연속된 참조는 **페이지 폴트**대상이\n아니기 때문입니다.\n\n<br>\n<br>\n\n## FIFO 페이지 교체 알고리즘\n\nFIFO 페이지 교체 알고리즘은 이름 그대로 먼저 들어온 페이지를 먼저 내보내는 방식입니다.\n\n![img.png](fifo.png)\n\n해당 그림을 통해 설명하면 2,3,1 번의 순서대로 프레임에 쌓이게 되며 마지막 1번 페이지가 적재 된 이후에는\n프레임이 가득차게 됩니다. 이후 3번은 이미 적재된 페이지이기 때문에 넘어갑니다.\n\n5번 페이지가 적재 되는 시점에 프레임은 가득 차있고, 5번페이지는 적재 되어있지 않기 때문에 **선별**후 **교체**하는\n작업이 필요합니다.\n\n여기서 **FIFO**방식은 가장 먼저들어온 페이지를 내보낸다라고 설명드린것처럼 처음들어온 **2페이지** **스왑아웃** 시키게 됩니다.\n빈 공간에 필요한 **5페이지**를 넣게 됩니다.\n\n이렇게 먼저 들어온 페이지를 먼저 내보내는것을 **FIFO 교체 알고리즘**이라고 명명합니다.\n\n하지만 이러한 방식에는 큰 단점이 있는데, 먼저 들어온 페이지가 실행 내내 사용 될 수도 있습니다.\n즉, 먼저 들어왔다고 해서 교체에 대상이 되기는 합당한 이유가 아니기 때문입니다.\n\n<br>\n<br>\n\n## 2차 기회 페이지 교체 알고리즘\n\n---\n\n해당 알고리즘은 **FIFO**방식을 개선한 알고리즘 입니다. 이름 처럼 한번의 기회를 더 주는 방식입니다.\n두가지 케이스가 있습니다. 기본적으로 가장 오래된 페이지를 **스왑 아웃**한다는 방식은 같습니다.\n만약 **스왑 아웃** 시점이 오게 되면, 해당 **참조 비트**를 확인합니다.\n\nCPU에 의해서 **참조** 된적이 있다면, 해당 **참조 비트**를 0으로 바꾸고 적재 시간을 현재로 변경하며,\n**참조 비트**가 0이라면 오래되면서 참조된적도 없기 떄문에 바로 **스왑 아웃** 시켜버립니다.\n\n<br>\n<br>\n\n## 최적 페이지 교체 알고리즘\n\n---\n\n**최적 페이지 교체** 방식은 이름그대로 최적의 방안을 찾는 알고리즘입니다.\n미래를 통해 오랫동안 사용되지 않을 페이지를 **스왑아웃** 시키면서 문제를 해결합니다.\n\n![img.png](optimal_page_replace.png)\n\n해당 그림을 통해 설명하면 5번 페이지를 요청할때 페이지 폴트가 발생하고 그 과정에서 이후 미래를 고려해서\n1번이 사용되지 않는다고 판단해 1번을 **스왑 아웃**하는 방식입니다.\n\n해당 알고리즘은 **페이지 폴트**가 가장 낮습니다.\n그렇지만, 현실적인 구현이 어렵습니다. 미래를 예측하는건 어려운 작업입니다. 그렇기 떄문에 현실적으로 가능한\n알고리즘으로 여기기 보단, **페이지 폴트**가 가장 낮다는 점을 고려하여 상대적인 **성능 평가**를 목적으로 사용합니다.\n\n다른 **교체 알고리즘**의 하한선으로 잡고 비교대상으로 쓰여집니다.\n\n<br>\n<br>\n\n## LRU 페이지 교체 알고리즘 (Least Recently Used Page Algorithm)\n\n---\n\n해당 알고리즘은 **최적 페이지 교체 알고리즘**을 변형해 **미래**를 예측하는것이 아닌, **과거**를 통해\n사용되지 않은 페이지를 **스왑아웃**하는 방식을 차용합니다.\n\n'최근에 사용되지 않은 페이지는 앞으로도 사용되지 않을 것이다' 라는 점을 토대로 구성됩니다.\n\n![img.png](lru.png)\n\n페이지마다 마지막으로 사용한 시간을 토대로 최근에 가장 사용이 적었던 페이지를 교체합니다.\n해당 그림에서는 5번 페이지가 적재될 시기에 가장 오래 사용되지 않는 **2**를 **스왑아웃** 시키는것을\n알 수 있습니다.\n\n<br>\n<br>\n\n## 스래싱과 프레임 할당\n\n---\n\n요구 페이징을 잘 수행하기 위해 **페이지 폴트**를 줄이는 방식을 이야기 했습니다.\n이러한 **페이지 폴트**를 줄이기 위해 **교체 알고리즘**을 적절하게 선택하는것이 중요하단것을 알게 되었습니다.\n\n하지만, **페이지 폴트**를 발생시키는 이유에는 **프레임 수의 한정**이라는 문제가 있습니다.\n프레임이 무지막지 하게 많다면 모든 프로세스를 할당할 수 있을것이고, 그렇게 되면 **스왑 아웃**이 발생할 이유도 없을것입니다.\n\n그렇기 때문에 **페이지 폴트**의 발생을 줄이기 위해 적절하게 **프레임을 할당**하는 것또한, 중요합니다.\n\n역으로 자원을 효율적으로 사용하고, 가상메모리와 같은 기법을 사용하면서 **페이징에 프로세스 실제 실행시간보다\n더큰 리소스를 사용**하는 문제가 생길 수도 있습니다.\n\n이렇게 배보다 배꼽이 큰 상황, 플어서 이야기하면\n> 페이징 시간이 프로세스 실제 실행보다 더 길어지는 상황\n\n을 **스레싱**이라고 부르게 됩니다.\n\n<br>\n\n### 멀티 프로그래밍 정도\n\n![img.png](degree_of_multiprogramming.png)\n\n해당 그래프는 세로축 **CPU 이용률**, 가로축 **메모리에 올라와 있는 프로세스 수**를 나타냅니다.\n그래프에서 알 수 있듯이 프로세스수가 증가하면, CPU이용률 또한 증가합니다 하지만 일정 가로축을 넘어가면\n**CPU**이용률이 줄어드는 것을 알게 됩니다.\n\n즉, 프로세스가 너무 많이 발생하면 각 프로세스에 할당된 **프레임**이 부족하고 그런 문제로 인해 **페이지 폴트**가\n자주 발생하게 됩니다.\n\nCPU를 아무리 좋은것을 사용해도 메모리 공간이 부족하면 컴퓨터 성능이 안좋아지는 이유가 이런이유입니다.\n\n<br>\n<br>\n\n# 프레임 할당\n\n---\n\n스래싱의 근본적 이유는 각 프로세스가 필요로 하는 **프레임**이 부족하기 때문입니다. 그렇기 떄문에\n운영체제는 **프레임**을 적절하게 할당할 수 있어야 합니다.\n\n이러한 **프레임 할당**을 크게 두가지로 나눌수 있습니다.\n\n1. 정적 할당 방식\n2. 동적 할당 방식\n\n<br>\n<br>\n\n## 정적 할당 방식\n\n---\n\n정적할당방식은 두가지로 나누어집니다.\n\n1. **균등할당**\n2. **비례할당**\n\n<br>\n\n### 균등할당\n\n균등할당은 이름에서 알 수 있듯이 모든 프로세스에 프레임을 균등하게 할당하는 방식입니다.\n프로세스가 3개가 있고, 프레임이 300개가 있다면 각 프로세스는 100개의 프레임을 할당받게 됩니다.\n\n이러한 방식은 프로세스 크기도 각자 다른 상황에서 합리적이지 못한 선택입니다.\n\n<br>\n\n### 비례할당\n\n크기가 큰 프로세스에 더 많은 프레임을 할당하는 방식을 비례할당이라고 부릅니다.\n하지만 이러한 방식은 **정적**이라는 한계점을 가지고 있습니다.\n\n실제 프로세스를 실행해보면 크기와 상관없이 더 많은 프레임을 필요로 하거나 그렇지 않은 프로세스들이 존재합니다.\n이러한 문제 떄문에 비례할당도 합리적이라고 할 수 없습니다.\n\n<br>\n\n## 동적 할당 방식\n\n---\n\n동적할당방식에는 크게 두가지로 나누어집니다.\n\n1. 작업 직합 모델(working set model)\n2. 페이지 폴트 빈도(PFF: page fault frequency)\n\n<br>\n\n### 작업 집합 모델\n\n작업 집합 모델에서는 '프로세스가 일정 기간 동안 참조한 페이지 집합'을 기억하며 빈번한 페이지 교체를 방지합니다.\n예를 들어 프로세스가 3초동안 20개의 페이지를 집중적으로 참조했다면 20개의 프레임을 할당하면 효율적일 것입니다.\n\n이렇게 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합을 **작업 집합**이라고 합니다.\n\n<br>\n<br>\n\n### 페이지 폴트 빈도\n\n![img.png](page_fault.png)\n\n페이지 폴트 빈도 방식은 해당 그래프를 통해 이루어 집니다.\n가로축은 할당된 프레임을 나타내며 세로축은 페이지 폴트율을 나타냅니다.\n할당된 프레임은 적으면 페이지 폴트가 많이 발생하는 형상이 됩니다.\n\n이러한 그래프에서 상한과 하한을 정한다음 해당 적정 구간에 들어올 수 있도록 프레임을 할당해주는\n방식을 **페이지 폴트 빈도**방식이라고 합니다.\n\n\n\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n"},{"excerpt":"연속 할당의 문제점 연속적 할당의 대표적인 문제점은 외부 단편화가 있습니다. 외부 단편화란 특정 프로세스를 실행시키기 위해\n필요한 공간이 있음에도 빈공간이 연속적이지 않아서 발생하는 문제입니다. 이러한 문제를 해결하기 위해서는 불연속 할당 방식 중 대표적인 페이징기법을 사용할 수 있습니다. 페이징이란?  페이징 기법은 프로세스를 일정한 단위로 자릅니다. …","fields":{"slug":"/22/"},"frontmatter":{"date":"September 25, 2025","title":"페이징","tags":["운영체제"]},"rawMarkdownBody":"\n### 연속 할당의 문제점\n\n---\n\n연속적 할당의 대표적인 문제점은 **외부 단편화**가 있습니다. 외부 단편화란 특정 프로세스를 실행시키기 위해\n필요한 공간이 있음에도 빈공간이 연속적이지 않아서 발생하는 문제입니다.\n\n이러한 문제를 해결하기 위해서는 **불연속 할당** 방식 중 대표적인 **페이징**기법을 사용할 수 있습니다.\n\n<br>\n<br>\n\n## 페이징이란?\n\n---\n\n![img.png](paging.png)\n\n페이징 기법은 프로세스를 일정한 단위로 자릅니다. 또한 프로세스가 들어갈 메모리 공간 또한 일정한 단위로 자릅니다.\n\n여기서 프로세스를 일정한 단위로 자르면 일정한 **논리 주소 공간**이 생기는데 이것을 **페이지**라고 부르며,\n일정한 단위로 잘린 메모리 **물리 주소 공간**은 **프레임**이라고 부르게 됩니다.\n\n여기서 **프레임**, **페이지**의 일정한 단위는 동일한 크기로 자르게 됩니다.\n\n이렇게 만들어진 **페이지**를 **프레임**에 할당하는 가상 메모리 관리 기법을 **페이징**기법이라고 부르게 됩니다.\n\n이렇게 일정한 크기를 정하고 불연속 할당을 수행하면 외부 단편화 문제를 줄일 수 있습니다.\n\n<br>\n\n### 페이징에서 스와핑\n\n![img.png](paging_swaping.png)\n\n페이징에서도 이전과 마찬가지로 **스와핑**이 사용됩니다. 차이가 있다면 기존 연속 할당 방식 스와핑은\n프로세스 전체가 스왑영역으로 넘어가지만, **페이징 스와핑**은 사용하지 않는 특정 **페이지**만 스왑아웃\n시킬 수 있습니다.\n\n이러한 방식은 이후 **가상메모리** 방식을 사용하는데 핵심이 됩니다.\n\n<br>\n\n## 페이지 테이블\n\n---\n\n불연속 할당 방식에는 실행순서에 대한 문제가 하나 있습니다. \n연속적 할당 방식에서는 실행순서를 CPU에게 알려줄 필요가 없습니다. 왜냐하면 실제로 물리 메모리에 연속적으로\n프로세스에 대한 정보가 있기 때문에 순서대로 실행시키면 되기 때문입니다.\n\n하지만, **불연속 할당**은 상황이 다릅니다. 메모리상 프로세스에 대한 정보가 연속적이지 않기 떄문에\n이를 실행시키는 **CPU**입장에서는 어떤 프로세스를 실행시켜야 할지 알기 어렵습니다.\n\n<br>\n\n![img.png](page_table.png)\n\n<br>\n\n이를 해결하기 위해서 **페이지 테이블**이란것을 사용합니다.\n\n**페이지 테이블**은 **페이지 번호**, **프레임 번호**를 짝지어 줍니다. 그렇게 되면 **CPU**입장에서는\n**페이지 번호**만 알고있다면 **페이지 테이블**을 통해 **프레임**으로 접근이 가능하기 때문입니다.\n\n페이지 테이블은 프로세스마다 각자의 페이지 테이블을 가지게 됩니다.\n\n<br>\n<br>\n\n## 페이지 테이블 베이스 레지스터(PTBR)\n\n---\n\n페이지 테이블은 프로세스마다 가지고 있고, 이는 **메모리**에 저장됩니다.\n\n하지만, CPU 입장에서는 결국 **페이지 테이블**의 위치를 알아야 합니다. 이러한 기능을 수행하는게\n**CPU**내의 존재하는 **PTBR**입니다.\n\n**PTBR**은 **CPU**내에 존재하고 **페이지 테이블**의 위치를 기록합니다.\n\n![img.png](ptbr.png)\n\n해당 그림처럼 특정 프로세스 작업을 수행하기 위해서 **CPU**는 해당 **PTBR**내부 프로세스의 페이지 테이블을\n조회합니다. 이후 메모리내부 해당 페이지 테이블 주소로 넘어가서 특정 프로세스의 페이지 까지 접근하게 됩니다.\n\n<br>\n<br>\n\n### 비효율적인 접근\n\n---\n\n이전 **페이지 테이블**을 참조하는데 한가지 문제가 있습니다.\n\n**CPU**는 **페이지 테이블**로 접근하고, 해당 값들을 통해 실제 **페이지**로 접근합니다.\n\n즉, 하나의 조회에 대해 두가지 접근을 수행하게 됩니다. 이러한 방식은 비효율적입니다.\n그렇기 때문에 **캐싱**기능을 통해 이를 해결하고 이러한 기능을 수행하는게 **TLB**입니다.\n\n<br>\n\n## TLB(Translation Lookaside Buffer)\n\n---\n\n![img.png](tlb.png)\n\n**TLB**는 CPU 곁에 존재하며 이는 페이지 테이블에 대한 **캐시 메모리**입니다.\n참조 지역성에 근거해 주로 최근에 사용된 페이지 위주로 가져와서 저장합니다.\n\n여타한 캐싱 기능과동일하게 리소스가 **TLB**를 통해서 나오게 되면, **히트**했다. 그것이 아니라면\n**미스**했다 라고 표현합니다.\n\n\n<br>\n<br>\n\n## 페이징에서의 주소 변환\n\n---\n\n**특정 주소**에 접근하기 위해서는 두가지 관점의 정보가 필요하게 됩니다.\n\n1. 어떤 페이지 혹은 프레임에 접근하고 싶은지\n2. 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져 있을지\n\n<br>\n\n이중에서 1번은 기존 **페이지 번호**를 통해서 해결할 수 있습니다.\n하지만, 2번의 말은 조금 애매하게 들리는데 이를 풀어서 설명하면,\n하나의 **주소**내에서도 **논리** 혹은 **물리**주소에 따른 순차적인 주소가 있습니다.\n\nn번지, n+1번지, n+2번지.... 처럼 세부적인 **지점**을 의미합니다.\n\n1번 주소를 통해서 **페이지**혹은 **프레임**에 접근한다면 그 중 명확한 지점을 식별해야 하기 때문에\n\n페이징 시스템에서는 **페이지번호**, **변위**를 이용합니다.\n\n자세한 예시는 아래 그림을 통해서 하겠습니다.\n\n<br>\n\n![img.png](paging_address_trans.png)\n\n페이지, 페이지 테이블, 프레임을 나타내는 그림입니다. 이러한 그림은 특정 페이지에 접근하기 위해\n페이지 테이블을 참조하고 프레임 번호를 얻어 실제 메모리 프레임에 접근하는 시퀀스 입니다.\n\n만약 **CPU**가 5번페이지에 변위가 2인 곳에 접근하려고 하면 10번지로 접근하게 될것입니다.\n\n1. 5번 페이지는 1번 프레임에 있다.\n2. 1번 프레임의 시작 번지수는 8번지이다\n3. 8번지에 변위 2를 더해서 최종주소는 10이 된다.\n\n여기서 주의 할점은, 논리주소의 변위를 최종 물리 주소상 프레임 번지에 더하였다는 것입니다.\n> 이말은, 논리주소의 변위 == 물리주소의 변위 입니다.\n\n이것이 가능한 이유는 처음 페이징 방식을 사용할때 페이지와 프레임 변환과정에서 **특정 크기**로 나누게 되고,\n그 간격이 같기 때문에 논리주소의 변위랑 물리주소의 변위는 같다는 결론이 나옵니다.\n\n<br>\n<br>\n\n## 페이지 테이블 엔트리\n\n---\n\n페이지 테이블 엔트리는 페이지 테이블 **row**를 지칭하는 단위입니다.\n\n![img.png](pte.png)\n\n지금까지는 이러한 페이지 테이블에는 페이지 번호, 프레임 번호만 존재 한다고 설명했습니다.\n하지만, 다른 중요한 정보들도 있습니다.\n\n1. 유효 비트\n2. 보호 비트\n3. 참조 비트\n4. 수정 비트\n\n<br>\n\n### 유효 비트\n\n유효비트는 해당 페이지에 접근 가능한지 여부를 알려줍니다. 대표적으로 접근 불가능 한 경우는\n**스와핑**으로 인한 해당 **페이지**가 **스왑영역**으로 들어간 경우입니다.\n\n이러한 경 **페이지 폴트**라는 예외가 발생하며, 하드웨어 인터럽트 처럼 처리 됩니다.\n\n1. CPU는 기존 작업 내역을 백업합니다.\n2. 페이지 폴트 처리 루틴을 실행합니다.\n3. 페이지 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경해줍니다.\n4. 페이지 폴트를 처리했다면 이제 CPU는 해당 페이지에 접근할 수 있게 됩니다.\n\n<br>\n\n### 보호 비트\n\n보호비트는 페이지 보호 기능을 위해 존재합니다. 리눅스의 읽기 쓰기 권한을 생각하면 됩니다.\n해당 페이지가 읽기 전용 페이지라면 보호비트는 0을 나타내고, 읽고 쓰기가 가능하다면 1을 나타냅니다.\n\n<br>\n\n### 참조 비트\n\n**CPU**가 접근한적 있는지 여부를 나타냅니다. 참조된 비트라면 1을 나타내며, 그렇기 않다면 0으로 유지됩니다.\n\n<br>\n\n### 수정 비트\n\n해당 페이지에 데이터를 쓴 적이 있는 여부를 나타냅니다. 수정 여부를 확인해야 하는 이유는 **스와핑** 떄문입니다.\n만약 **CPU**가 페이지에 대한 내용을 수정했다면, 스와핑 과정에서 보조 기억장치에 있는 데이터 또한 수정해야 하기 때문입니다.\n\n\n\n\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n"},{"excerpt":"연속 메모리 할당  연속 메모리 할당이란 메모리에 프로세스가 그림처럼 연속적으로 배치되는 상황을 가정합니다. 프로세스 A가 할당되고, 남는 주소만큼 이어서 B,C,D...를 할당하는 방식입니다. 이런 방식은 예제를 위한 단편적인 설명만 가능한데 이유는 아래에서 설명할 스와핑과 관련이 있습니다. 스와핑이란? 메모리는 실행시킬 프로세스를 적재하게 됩니다. 하…","fields":{"slug":"/21/"},"frontmatter":{"date":"September 24, 2025","title":"메모리 배치기법 그리고 단편화에 대해","tags":["운영체제"]},"rawMarkdownBody":"\n## 연속 메모리 할당\n\n---\n\n![img.png](sequencial_memory.png)\n\n**연속 메모리 할당**이란 메모리에 프로세스가 그림처럼 **연속적**으로 배치되는 상황을 가정합니다.\n\n프로세스 A가 할당되고, 남는 주소만큼 이어서 B,C,D...를 할당하는 방식입니다.\n\n이런 방식은 예제를 위한 단편적인 설명만 가능한데 이유는 아래에서 설명할 **스와핑**과 관련이 있습니다.\n\n<br>\n\n## 스와핑이란?\n\n---\n\n메모리는 실행시킬 프로세스를 적재하게 됩니다. 하지만, 이런 프로세스들 중에 현재 실행되지 않는 프로세스는 처리해줘야 합니다.\n메모리 리소스가 한정적이기 때문입니다.\n\n여기서 말하는 실행되지 않는 프로세스의 예시는 **I/O**작업, 오랫동안 사용되지 않는 프로세스가 이에 해당합니다.\n\n<br>\n\n![img.png](swaping.png)\n\n<br>\n\n그렇다면 이러한 프로세스를 메모리에서 처리하는 방법이 필요한데 그 방법이 **스와핑** 입니다.\n\n**스와핑**은, 두가지 행위를 통해서 수행할 수 있습니다.\n\n> 스왑 아웃: 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것 (메모리 -> 스왑 영역)\n\n> 스왑 인: 스왑영역에 있던 프로세스가 다시 메모리로 옮겨지는 것 (스왑 영역 -> 메모리)\n\n또한 메모리에서 보조기억장치로 옮겨질때 **스왑영역**으로 프로세스를 옮겨두는데 그 영역을 **스왑 영역**이라고 합니다.\n\n<br>\n<br>\n\n## 메모리 할당 방식\n\n---\n\n프로세스는 메모리 속 비어있는 공간에 적재되어야 합니다. 비어 있는 메모리 공간에 프로세스를 연속적으로 할당하기 위해\n**세가지** 방법을 고려할 수 있습니다.\n\n1. **최초 적합(first fit)**\n2. **최적 적합(best fit)**\n3. **최악 적합(worst fit)**\n\n각방식을 아래 예시를 통해 들어보려 합니다.\n\n프로세스 A,B,C는 이미 적재되어있고, 빈 공간 A,B,C가 있습니다. 앞으로 적재할 프로세스는 20MB크기를 가지고 있으며\n적재 방식에 따라 이를 어디에 적재할지 달라지게 됩니다.\n\n![img.png](memory_stacking.png)\n\n<br>\n\n## 최초 적합\n\n---\n\n최초 적합은 메모리 내의 빈 공간을 순서대로 검색하다가 적재할 수 있는 공간을 발견하면 그 공간에 프로세스를 배치하는 방식입니다.\n이전 그림에서 운영체제가 빈공간 A,B,C 순서대로 검색을 하였다면 가장 먼저 검색된 A 빈공간에 적재되는 방식입니다.\n\n![img.png](first_fit.png)\n\n적재후 모습은 그림과 같으며 해당 방식은 검색을 최소화 하며 **빠른 할당**을 가능하게 하는 장점이 있습니다.\n하지만, 이후에 보게 될 **외부 단편화**가 생길 가능성이 높아지게 됩니다.\n\n<br>\n<br>\n\n## 최적 적합\n\n---\n\n최적 적합은 운영체제가 빈공간을 **모두** 검색한 후 프로세스가 적재될 수 있는 공간 중 가장 **작은 공간**에 프로세스를\n배치하는 방식입니다.\n이전 그림에서는 빈 공간 C가 가장 적합한 크기를 가진 공간이기 때문에 그곳에 적재 됩니다.\n\n![img.png](best_fit.png)\n\n적재후 모습은 그림과 같으며 해당 방식은 적재할 프로세스 크기를 고려한 방식이기 때문에 **외부 단편화**를 \n최소화 할 수 있다는 장점이 있지만, **모든**공간을 검색하는 행위가 **오버헤드**를 발생시키기 때문에 느려집니다.\n\n<br>\n<br>\n\n## 최악 적합\n\n---\n\n최악 적합은 운영체제가 빈 공간을 모두 검색한 후, 가장 큰 공간에 프로세스를 적재하는 방식입니다.\n\n![img.png](worst_fit.png)\n\n적재 후 모습은 가장 빈공간의 크기가 큰 B에 적재되는 것을 확인할 수 있습니다. 이러한 방식은\n외부 단편화의 발생 빈도도 크며, 모든 공간을 검색한다는 비효율적인 측면도 가지고 있습니다.\n\n<br>\n\n지금까지 **외부 단편화**라는 용어가 단점으로 설명했습니다.\n그렇다면, **외부 단편화**는 어떠한 문제일까요?\n\n<br>\n\n## 단편화\n\n---\n\n단편화는 크게 두가지로 나눌 수 있습니다.\n\n1. 내부 단편화\n2. 외부 단편화\n\n<br>\n\n### 내부 단편화\n\n![img.png](first_fit.png)\n\n내부 단편화 문제는 이전 **최초 적합** 사례에서 볼 수 있습니다.\n빈공간A의 크기는 30MB인데 적재한 프로세스는 20MB입니다. 이런경우 10MB의 빈공간이 생기게 되고 이러한 비어있는\n공간을 **내부 단편화**가 발생했다고 표현합니다.\n\n<br>\n\n### 외부 단편화\n\n![img.png](first_fit.png)\n\n외부 단편화 문제는 이전 **최초 적합** 사례를 이어서 설명하겠습니다.\n현재 그림속 비어있는 공간은 **80MB**입니다. 하지만 해당 공간에 **80MB**크기의 프로세스를 적재할 수 없습니다.\n이유는, 빈 공간이 연속적인것이 아닌 프로세스C에 의해 끊어져있기 때문입니다.\n\n이처럼, 프로세스를 할당하기 어려울 만큼 작은 메모리 공간들로 인해 메모리가 낭비되는 현상을 지칭합니다.\n\n이러한 외부 단편화를 해결할 수 있는 대표적인 방안은 메모리를 **압축**하는 방법이 있습니다.\n\n<br>\n\n## 압축\n\n---\n\n**압축**이란 흩어져 있는 빈 공간들을 하나로 모으는 방식으로 메모리 내에 저장된 프로세스를 재배치 시켜 빈 공간을\n하나의 큰 빈 공간으로 만드는 방법입니다.\n\n이러한 방식은 단점이 있는데, 메모리의 빈공간을 모으는 작업은 시스템을 중지 시킨다는 문제가 있습니다.\n또한, 메모리를 옮기는 작업이 큰 오버헤드를 만들고, 최적화 방법에 대한 정답을 고르기가 어렵습니다.\n\n\n\n\n\n\n\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n\n\n\n\n\n\n\n"},{"excerpt":"물리주소와 논리주소  메모리는 보조기억장치로 부터 실행될 프로그램을 받아서 저장합니다.\n이 저장된 메모리의 데이터를 CPU 혹은 실행중인 프로그램이 읽어 실행하게 됩니다. 해당 그림은 두가지 관점으로 주소를 나누고 사용하는 방식을 그림으로 나타낸 것입니다. 왜, 주소를 두가지 방식으로 나누어서 사용하게 되었을까요? 이유는 메모리에 저장되어 있는 정보는 변…","fields":{"slug":"/20/"},"frontmatter":{"date":"September 23, 2025","title":"물리주소, 논리주소 그리고 메모리 분할 방식","tags":["운영체제"]},"rawMarkdownBody":"\n## 물리주소와 논리주소\n\n---\n\n![img.png](memory_address.png)\n\n메모리는 보조기억장치로 부터 실행될 프로그램을 받아서 저장합니다.\n이 저장된 메모리의 데이터를 **CPU** 혹은 **실행중인 프로그램**이 읽어 실행하게 됩니다.\n\n해당 그림은 두가지 관점으로 **주소**를 나누고 사용하는 방식을 그림으로 나타낸 것입니다.\n\n왜, 주소를 두가지 방식으로 나누어서 사용하게 되었을까요?\n\n> 이유는 메모리에 저장되어 있는 정보는 변화가 빠르고 이를 시시각각 알기어렵기 때문에\n\n가령 프로그램이 새롭게 실행될때, 삭제 될때 혹은 같은 프로그램일지라도 실행될때마다 실행되는 주소가 다르기 때문입니다.\n\n그렇기때문에 주소를 두가지 관점으로 나눠서 사용하게 됩니다.\n\n> **물리주소**란 실제로 정보가 저장된 하드웨어상 주소를 의미합니다.\n\n> **논리주소**란 실행중인 프로그램에 부여된 0번지부터 시작되는 주소를 의미합니다.\n\n여기서 주의할점은 **논리주소**는 0번지 부터 시작하는 논리적 주소이기 때문에, **고유성**이 없습니다. 하지만 **물리주소**는\n하드웨어상 주소기 때문에 **고유성**이 있습니다.\n\n<br>\n<br>\n\n## 메모리 할당 방식\n\n---\n\n**메모리 할당**이란 주기억 장치에 프로세스를 저장하는 과정입니다.\n이러한 과정은 크게 **두가지**로 나누어집니다.\n\n1. 연속 할당\n2. 불연속 할당\n\n<br>\n\n## 연속할당\n\n---\n\n연속 할당은 프로세스가 연속된 메모리 영역에 할당되는 방법을 말합니다.\n각 프로세스는 연속적인 메모리 주소 범위 내에 위치하게 됩니다. 이렇게 연속할당을 하게 되면\n빈공간보다 프로세스 공간이 더 작은 경우가 있는데 이러한 현상을 **단편화**라고 합니다.\n\n연속할당의 종류로는 **고정 크기 파티셔닝**, **가변 크기 파티셔닝**이 있습니다.\n\n<br>\n\n### 고정 크기 파티셔닝\n\n고정 크기 파티셔닝은 메모리를 고정된 크기의 파티션으로 나누어 각 파티션에 프로세스를 할당하는 방식입니다.\n예를들어, 모든 파티션을 10MB로 설정하고 파티션마다 프로세스를 할당하는 방식을 사용할 수 있습니다.\n\n이러한 방식은 모든 프로세스가 지정한 파티션 크기만큼 떨어지는것이 아니기 떄문에 효율적이지 못한 단점이 있습니다.\n\n<br>\n\n### 가변 크기 파티셔닝\n\n가변 크기 파티셔닝은 파티션의 크기를 유동적으로 조절하는 메모리 할당 방식입니다.\n이러한 방식은 **고정 크기 파티셔닝**보다는 효율적이지만, 메모리 공간에 어떤 프로세스를 저장해야 할지 결정하는게\n복잡합니다.\n\n<br>\n<br>\n\n## 불연속 할당\n\n---\n\n불연속 할당은 한 프로세스를 메모리 여러 곳에 분산 저장하는 방법입니다. **페이징**, **세그멘테이션** 이 있습니다.\n\n<br>\n\n### 페이징\n\n페이징은 프로세스의 주소 공간을 페이지라는 동일한 크기의 구획으로 나누고, 주기억 장치도 페이지와 동일한 크기의\n프레임이라는 구획으로 나눕니다. 이후 한 페이지를 한 프레임에 적재하는 방식입니다.\n\n자세한 내용은 이후에 다루게 됩니다.\n\n<br>\n\n### 세그멘테이션\n\n프로세스의 주소공간을 세그먼트라는 단위로 나누어 주기억 장치에 적재합니다.\n프로세스는 코드, 데이터, 스택 등으로 구성되기 때문에 각각을 한 세그먼트로 나누어서 메모리에 적재합니다.\n\n이 과정에서, base주소와, limit주소를 이용하여 프로세스가 자신에게 할당된 메모리 영역만 사용하게 합니다.\n\n\n<br>\n\n\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n\n\n"},{"excerpt":"교착상태란?(Dead Lock) 교착상태란 두개 이상의 프로세스가 각자 가지고 있는 자원을 무작정 기다리는것을 말합니다. 교착상태를 설명하는 대표적인 예시로 식사하는 철학자 문제라는게 있습니다. 식사하는 철학자  식사하는 철학자 문제는 그림처럼 동그란 원탁에 다섯명의 철학자가 앉아 있습니다. 이 철학자들은 각각 식사를 배정받고, 식사에 필요한 포크도 있습…","fields":{"slug":"/19/"},"frontmatter":{"date":"September 22, 2025","title":"교착상태와 해결 방법","tags":["운영체제"]},"rawMarkdownBody":"\n## 교착상태란?(Dead Lock)\n\n---\n\n**교착상태**란 두개 이상의 프로세스가 각자 가지고 있는 자원을 무작정 기다리는것을 말합니다.\n\n**교착상태**를 설명하는 대표적인 예시로 **식사하는 철학자 문제**라는게 있습니다.\n\n<br>\n\n### 식사하는 철학자\n\n---\n\n![img.png](dpp.png)\n\n<br>\n\n식사하는 철학자 문제는 그림처럼 동그란 원탁에 다섯명의 철학자가 앉아 있습니다. 이 철학자들은 각각 식사를 배정받고, 식사에 필요한 포크도 있습니다.\n식사를 하려면 두개의 포크를 들어야 하는 상황입니다.\n\n이를 순서도로 표현하면\n\n1. 생각을 하다가 왼쪽 포크를 들 수 있다면 든다.\n2. 생각을 하다가 오른쪽 포크를 들 수 있다면 든다.\n3. 왼쪽, 오른쪽 포크를 모두 집어들면 정해진 시간동안 식사를 한다.\n4. 식사 시간이 끝나면 오른쪽 포크를 내려놓는다.\n5. 나머지 왼쪽 포크도 내려놓는다.\n6. 1번부터 반복한다.\n\n<br>\n\n위와같은 상황일때 모든 철학자가 왼쪽 포크를 들고 있거나, 반대쪽 포크를 들고 있다면 식사는 영원히 끝나지 않습니다. 이유는 포크라는 자원은\n철학자의 수만큼 존재하고 각 철학자는 두개의 포크를 원하는 상태에서 모든 포크를 얻을때까지 가디라기 떄문에, 모든 철학자가 포크를 기다리기만 하는\n상황이 발생합니다.\n\n이러한 문제는 **일어나지 않을 사건을 기다리며 진행이 멈춰 버리는** **교착상태**와 같습니다.\n\n여기서 철학자를 **프로세스 혹은 스레드** 포크를 **자원** 그리고 생각하는 행위가 자원을 기다리는 것이라고 생각한다면, 프로세스와 스레드는\n**자원**을 사용하기 위해 **기다리는 행위**만 계속하는 상황이 되는것입니다.\n\n<br>\n<br>\n\n## 교착상태 발생조건\n\n---\n\n교착상태가 발생할 조건에는 네가지가 있습니다. 차례대로 **상호배제**, **점유와 대기**, **비선점**, **원형 대기**입니다. 해당 조건은\n모두 만족해야지 **교착상태**가 발생하고 하나라도 해당하지 않는다면 **교착상태**는 발생하지 않습니다.\n\n<br>\n\n### 1. 상호 배제\n\n교착 상태가 발생한 근본적인 원인은 해당 자원을 하나의 프로세스만 사용하기 때문입니다. 프로세스도 마찬가지로 한 프로세스가 사용하는 자원을 다른 프로세스가\n사용할 수 없을때, 교착상태가 발생합니다.\n\n### 2. 점유와 대기\n\n프로세스는 자원을 할당받은 상태에서 다른 자원을 할당받기를 기다린다면 교착 상태가 발생할 수 있습니다. 이렇게 **자원을 할당받은 상태에서 다른 자원을\n할당받기를 기다리는 상태**를 **점유와 대기**라고 합니다.\n\n### 3. 비선점\n\n이전에 **선점**, **비선점**이라는 개념을 보았습니다. **비선점**이란 프로세스나 스레드가 자원을 할당받으면 그 작업이 끝나기전까지 자원을 뻇어갈수 없다는\n특징이 있었습니다. 교착상태가 발생하는 원인은 **점유와 대기**상태중 필요한 자원을 **선점**할수 없이 계속 기다리기만 하여서 발생하는 문제 입니다.\n\n### 4. 원형 대기\n\n**자원 할당 그래프**가 원의 형태로 그려지면 교착 상태가 발생할 수 있습니다. 이렇게 프로세스들이 원의 형태로 자원을 대기하는 것을 **원형 대기**라고 합니다.\n\n<br>\n<br>\n\n## 교착상태 해결방법\n\n---\n\n교착상태를 해결하는 방법은 크게 세가지로 나눌수 있습니다.\n> 1. 예방\n> 2. 회피\n> 3. 검출 후 회복\n\n<br>\n<br>\n\n## 예방을 통한 해결\n\n---\n\n예방이란 교착상태 발생 조건에 부합하지 않게 자원을 분배하는 방식입니다.\n\n이전에 말한 **교착상태**발생 조건에 해당하는 네 가지 중 하나를 충족 하게 되면 **교착 상태**를 해결할 수 있습니다.\n\n### 상호 배제를 없애는 방식\n\n> 이론적으로는 가능하나, 모든 자원이 상호 배제를 없애기는 어렵기 때문에 비현실적이다.\n\n<br>\n\n### 점유와 대기를 없애는 방식\n\n> 특정 자원이 먼저 점유를 수행하여 작업을 끝내고, 다른 프로세스에게 자원을 몰아주는 방식으로 해결이 가능합니다.\n> \n> 하지만 이런 방식은 자원 활용률이 낮아 진다는 문제가 있습니다.\n\n<br>\n\n### 비선점 조건을 없애는 방식\n\n> 비선점 방식으로 작업을 다루게 되면 교착상태가 발생해도 자원을 뺏어 해결 할 수 있습니다.\n> \n> 하지만, 이런방식의 문제점은 모든 자원이 비선점 기능을 사용할 수 없다는 점에 있습니다.\n> \n> 예를들어, 프린터는 비선점 방식을 수행하는 자원입니다.\n\n<br>\n\n### 원형 대기 조건을 없애는 방식\n\n> 모든 자원에 번홀을 붙이고 오름차순으로 자원을 할당하면 원형 대기는 방생하지 않습니다.\n> 마치 원형이 아닌, 선형으로 자원을 나열하는 방식입니다.\n> \n> 이런 방식은 자원에 일일이 번호를 붙여야 한다는점과, 특정 번호는 자원 활용률이 떨어질수 있다는 문제가 있습니다.\n\n<br>\n<br>\n\n## 회피를 통한 해결\n\n---\n\n회피 방식에서는 교착 상태 발생이 한정된 자원을 무분별하게 할당하였서 그렇다고 가정합니다. 그렇기 때문에 회피방식은 자원을 신중하게 할당하는 방식으로\n해결합니다.\n\n즉, 교착 상태가 발생하지 않을 정도의 양만큼만 자원을 배분하는 방법을 **교착 상태 회피**라고 부릅니다.\n\n**안정 상태**, **불안전 상태**가 있습니다. 각각 교착상태가 발생하지 않는 상태를 **안정상태**, 발생할 가능성이 있는 상태를 **불안정 상태**라고 부릅니다.\n\n**회피**를 통해 교착상태를 해결하기 위해 **안전 순서열**을 고려해서 문제를 해결합니다.\n\n> 안전순서열: 교착 상태 없이 안전하게 프로세스들에 자원을 할당할 수 있는 순서를 의미합니다.\n\n<br>\n\n내용을 종합하면 **안전 순서열**이 있고 그것을 사용할때 상태를 **안정상태**, 안전 순서열이 없을 때 상태는 **불안정상태**라고 부르게 됩니다.\n\n<br>\n<br>\n\n## 교착 상태 검출 후 회복\n\n---\n\n마지막으로, 교착상태를 피하기 위해서는 **검출**, **회복** 방식을 사용합니다.\n\n두가지 방식을 고려할 수 있는데,\n\n1. 선점을 통한 회복\n2. 프로세스 강제종료\n\n<br>\n\n### 선점을 통한 회복\n\n교착 상태가 해결될 때까지 한 프로세스씩 자원을 몰아주는 방식입니다. 교착 상태가 해결될 떄까지 다른 프로세스로부터 자원을 빼앗고 할당하는 방식입니다.\n\n<br>\n\n### 강제종료를 통한 회복\n\n교착 상태에 놓인 순간 모든 프로세스를 종료 하는 방법 혹은 프로세스를 하나씩 종료해서 확인해보는 방법이 있습니다.\n\n전자는 가장 확실하지만 모든 작업에 대한 진행사항을 잃을 가능성이 있고, 후자는 전자보다 손실에 대한 부담은 적지만 오버헤드가 커진다는 단점이 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n\n"},{"excerpt":"상호배제(Mutual Exclusion) 상호배제(Mutual Exclusion)는 여러 프로세스나 스레드가 동시에 같은 공유 자원에 접근하는 것을 막는 메커니즘입니다. 일상생활에서 비유하면, 화장실 사용과 같습니다.\n한 번에 한 사람만 화장실을 사용할 수 있고, 다른 사람들은 기다려야 합니다.\n컴퓨터 시스템에서도 마찬가지로 특정 자원은 한 번에 하나의 …","fields":{"slug":"/18/"},"frontmatter":{"date":"September 21, 2025","title":"상호배제와 동기화 기법","tags":["운영체제"]},"rawMarkdownBody":"\n## 상호배제(Mutual Exclusion)\n\n---\n\n상호배제(Mutual Exclusion)는 여러 프로세스나 스레드가 동시에 같은 공유 자원에 접근하는 것을 막는 메커니즘입니다.\n\n일상생활에서 비유하면, 화장실 사용과 같습니다.\n한 번에 한 사람만 화장실을 사용할 수 있고, 다른 사람들은 기다려야 합니다.\n컴퓨터 시스템에서도 마찬가지로 특정 자원은 한 번에 하나의 프로세스만 사용할 수 있어야 합니다.\n\n<br>\n\n## 왜 상호배제가 필요할까?\n현대 운영체제는 멀티태스킹 환경에서 여러 프로세스가 동시에 실행됩니다.\n이때 프로세스들이 공유하는 자원(메모리, 파일, 데이터베이스 등)에 동시에 접근하면 다음과 같은 문제가 발생할 수 있습니다.\n\n### 1.경쟁 상황(Race Condition)\n\n두 프로세스가 동시에 같은 데이터를 수정하려 할 때, 실행 순서에 따라 결과가 달라지는 상황입니다.\n예를 들어, 은행 계좌 잔액을 동시에 업데이트하는 두 거래가 있다면, 최종 잔액이 예상과 다를 수 있습니다.\n\n### 2. 데이터 일관성 파괴\n\n여러 프로세스가 동시에 데이터를 수정하면 데이터의 무결성이 깨질 수 있습니다. 이는 시스템 전체의 신뢰성에 큰 영향을 미칩니다.\n\n<br>\n<br>\n\n## 동기화 기법\n\n---\n\n이런 **상호 배제**에 대해 방지하는 방법으로는 **뮤텍스**, **세마포어**, **모니터** 기법이 있습니다.\n\n<br>\n<br>\n\n## 뮤텍스 락(Mutex lock)\n\n---\n\n**뮤텍스 락**의 풀네임은 **Mutual Exclusion Lock**입니다. 즉 상호 배제 단어에 lock을 붙인 단어와 일치합니다.\n\n이 말은 상호배제를 구현하기 위해 **Locking**방식을 사용하는 방법입니다.\n\n**뮤텍스 락**은 화장실 사용에 비유해보겠습니다.\n\n![img.png](toilet.png)\n\n<br>\n\n화장실은 한칸에 한사람만 받을 수 있습니다. 칸에 사람이 들어가있다면 해당 칸에 다른 사람이 들어올 수 없습니다.\n다른 사람이 들어오는 시점은 먼저 사용하던 사람이 해당 칸을 나가게 되면 사용할 수 있습니다.\n\n이 내용을 설명하는 이유는, 위 방식의 흐름이 뮤텍스 락과 동일하기 때문입니다.\n\n간단한 **뮤텍스락**을 코드를 통해서 보겠습니다.\n\n**자물쇠**에 해당하는 전역변수 하나, 그리고 해당 **자물쇠**를 잠구고, 푸는 두가지 함수만 있으면 구현가능합니다.\n\n<br>\n<br>\n\n````java\nacquire(){\n    while (lock == true){\n        .....\n        }\n    \n    lock = true;\n}\n````\n\n````java\nrelease(){\n    lock = false;\n        }\n````\n\n<br>\n\n해당 함수들은 차례대로 화장실 문이 잠겼는지 확인하고 잠기지 않았다면 들어가서 잠구는 함수 **Acquire**,\n그리고 화장실을 나올때 잠금을 해제 하는 **Release**로 볼 수 있습니다.\n\n이 함수를 아래 수도코드 처럼, 임계 구역 들어가기전, 나온 후 에 사용하게 되면\n\n````java\nacquire();\n// 임계 구역\nrelease();\n````\n\n**lock**여부를 확인 한 후, 들어가도 되면 본인이 **lock**을 걸고 이미 **lock**이 걸려있다면\n임계 구역 코드 전에서 계속 기다리게 됩니다.\n\n<br>\n\n### 뮤텍스 락의 단점\n\n\n하지만, 이런 방식에는 큰 문제가 있는데 **바쁜대기(Busy Wait)** 을 수행하게 됩니다.\n명칭 그대로 대기를 하는 상황임에도 바쁘게 행동하는 것을 말하게 됩니다.\n\n**대기**를 하는 상황에 행동을 하는것은 **lock 확인**작업에 **CPU**를 사용하겠다는 것을 의미하고,\n이런 기다림은 해당 **lock** 이 풀릴떄까지 지속됩니다. 즉, 비효율적입니다.\n\n<br>\n<br>\n\n## 세마포(semaphore)\n\n---\n\n**세마포**는 동기화 방식중 하나입니다. **뮤텍스 락**과 비교하면 공유자원의 갯수를 다루는 방식이 다릅니다.\n**뮤텍스 락**은 공유자원이 하나라고 가정하고 라킹을 수행하지만, **세마포**는 공유 자원이 여러 개 있을경우\n각 프로세스는 해당 공유자원에 접근이 가능합니다.\n\n마치 공중화장실에서 화장신 칸 수 만큼 공유자원이 있고, 각 칸에 사람이 들어가는 것을 관리하는 방식입니다.\n\n![img.png](semaphore.png)\n\n**세마포**는 사진과 같은 **철도 신호기**에서 유래한 단어 입니다. 그렇기 때문에 철도 신호와 같은 방식을 사용합니다.\n\n**뮤텍스 락**은 공유 자원을 **잠금**, **해제**를 수행하면서 해당 자원을 관리하지만,\n\n**세마포**의 경우 **빨간불**, **초록불** 처럼 가도 되는지, 멈춰야 하는지 상태를 알려줍니다.\n\n**세마포**도 간단하게 코드로 구현이 가능합니다.\n\n먼저 **공유자원의 갯수**를 나타내는 전역 변수 한개와, 임계구역에 들어가도 되는지, 기다려야 할지 알려주는 함수 **Wait**,\n그리고 기다리고 있는 프로세스에게 **이제 출발하라**를 나타내는 **Signal**함수가 있습니다.\n\n<br>\n\n````java\nwait() {\n    while(S <= 0){\n        \n        }\n    S--;\n}\n````\n\n````java\nsignal() {\n    S++;\n}\n````\n\n위 코드를 차례대로 **Wait**, **Signal**함수를 구현한것이고 전역 변수 S의 값이 양수, 즉 사용해도 되는\n공유자원이 있을 경우 **Wait**함수의 while문을 탈출합니다.\n\n그 경우 사용가능한 공유 자원 갯수를 하나 줄입니다.\n\n````java\nwait();\n// 임계 구역\nsignal();\n````\n\n임계 구역을 나오게 되면 signal이 수행될것이고, 사용가능한 자원을 하나 반납하게 될것입니다.\n\n<br>\n\n근데 while문이 있다면 **뮤텍스락**처럼  **바쁜 대기** 상태가 발생할 수 있다는걸 암시하게 됩니다.\n하지만 이는 세마포가 **CPU**를 사용하지 않게 구현하며 해결할 수 있습니다.\n\n<br>\n\n## 세마포가 busy wait를 해결하는 방법\n\n---\n\n아래 두가지 함수를 통해서 세마포는 **busy wait**를 해결합니다.\n\n````java\nwait(){\n    S--;\n    if ( S < 0){\n        add this process to Queue;\n        sleep();\n    }\n}\n````\n\n````java\nsignal(){\n    S++\n    if ( S <= 0){\n        remove a process p from Queue;\n        wakeup(p);\n        }        \n}\n````\n위 방식은 이전처럼 while문을 통한 접근 가능여부를 체크하는 것이 아닌 만약 접근 불가능 한경우(사용가능한 공유 자원이 없을떄)\n해당 프로세스의 **PCB**를 **세마포**를 위한 **대기 큐**에 넣습니다.\n\n프로세스는 대기 큐에 들어가게 되면서 이후 해당 **PCB**를 **준비 큐**로 돌리기 전까지 **CPU**자원을 잡아 먹지 않게 됩니다.\n\n<br>\n<br>\n\n## 모니터\n\n---\n\n세마포 기법 자체는 동기화도구로써 좋은 효능을 보여주지만, 사용자 측면에서 불편한 점이 있다.\n임계 구역에 앞뒤로 wait, signal 함수를 사용하고 휴먼에러로 인한 실수가 발생한다면 예기치 못한 결과를 발생시킬 수 있기 때문이다.\n\n이에 **모니터**라는 동기화 도구가 생기게 된다.\n\n모니터는 공유 자원과, 공유 자원에 접근하기 위한 인터페이스를 묶어 관리합니다.\n\n<br>\n\n![img.png](monitor.png)\n\n<br>\n\n이를 위해 모니터를 통해 공유 자원에 접근하고자 하는 프로세스를 큐에 삽입하고, 큐에 삽입된 순서대로 하나씩 공유 자원을 이용하도록 합니다.\n모니터는 공유 자원을 다루는 인터페이스에 접근하기 위한 큐를 만들고, 모니터 안에 항상 하나의 프로세스만 들어오도록 하여 **상호 배제**를 수행합니다.\n\n또한, 모니터는 **실행 순서**를 제어하는 동기화 또한 수횅합니다. **조건 변수**를 사용해서 실행 순서를 제어하게 됩니다.\n\n<br>\n\n![img.png](monitor2.png)\n\n<br>\n\n해당 그림처럼 기존 **상호 배제를 위한 큐**가 아닌 **조건 변수**에 대한 큐가 있습니다. 이 **조건 변수**는 기존처럼 **wait**, **signal** 연산을\n수횅할 수 있습니다.\n\n상호 배제를 위한 큐에서 가장 선두에 있는 프로세스A보다 특정 프로세스B가 더 먼저 시행되어야 한다면, B가 수행되기 전까지 앞선 프로세스들은 **wait** 연산을 통해\n조건 변수에 대한 큐에서 대기하게 되고, 그렇게 대기를 하게되면 최우선 시행되는 프로세스는 **B**가 될것입니다. 이런 형태로 모니터는 실행 순서를 제어합니다.\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n\n"},{"excerpt":"공유자원 동시에 실행되는 프로세스에서 공통으로 사용하는 자원을 우리는 공유자원이라고 부릅니다. 임계구역(Critical Section) 공유 자원을 사용하는 여러개의 프로세스 중, 해당 공유 자원에 접근하는 코드 영역을 임계 구역이라고 부릅니다. 두 개 이상의 프로세스가 임계 구역에 진입하고자 하면 둘 중 하나는 대기해야 합니다. 임계 구역에 먼저 진입한…","fields":{"slug":"/17/"},"frontmatter":{"date":"September 20, 2025","title":"임계구역과 경쟁상태","tags":["운영체제"]},"rawMarkdownBody":"\n### 공유자원\n\n---\n\n동시에 실행되는 프로세스에서 **공통**으로 사용하는 자원을 우리는 **공유자원**이라고 부릅니다.\n\n<br>\n<br>\n\n## 임계구역(Critical Section)\n\n---\n\n공유 자원을 사용하는 여러개의 프로세스 중, 해당 공유 자원에 접근하는 코드 영역을 **임계 구역**이라고 부릅니다.\n\n두 개 이상의 프로세스가 임계 구역에 진입하고자 하면 둘 중 하나는 대기해야 합니다. 임계 구역에 먼저 진입한 프로세스의\n작업이 마무리되면 그제서야 기다렸던 프로세스가 임계 구역에 진입 합니다.\n\n![img.png](critical_section.png)\n\n\n<br>\n<br>\n\n## 경쟁상태(Race Condition)\n\n---\n\n**임계 구역**은 두 개 이상의 프로세스가 동시에 실행되면 안 되는 영역이지만, 잘못된 실행으로 여러 프로세스가\n**공유 자원**을 사용하는 경우에 문제가 발생합니다.\n이러한 문제를 **경쟁 상태**라고 합니다.\n\n이러한 **경쟁 상태**는 데이터의 일관성이 깨지는 문제를 발생시킵니다.\n\n<br>\n<br>\n\n## 운영체제가 임계구역 문제를 해결하는 세가지 원칙\n\n---\n\n### 1. 상호배제: 한 프로세스가 임계 구역에 진입했다면 다른 프로세스가 들어올 수 없다.\n### 2. 진행: 임계구역에 어떤 프로세스도 진입하지 않았다면 진입하고자 하는 프로세는 들어갈 수 있어야 한다.\n### 3. 유한 대기: 한 프로세스가 임계구역에 진입하고 싶다면 언젠가는 임계구역에 들어갈 수 있어야 한다.(무한정 대기x)\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n"},{"excerpt":"병행성(Concurrency)  병행성은 다른 말로 동시성이라고 부르는 용어입니다.\n이전까지 보았던 싱글 코어에서 프로세스를 처리하기 위해 많은 프로세스들을 컨텍스트 스위칭을 통해 효율적으로 프로세스를 처리했던것 기억할것 입니다.\n이경우 프로세스를 동시에 처리한다고 표현하지만 사실 이는 빠른 속도로 프로세스를 스위칭해서 실행시키는 것이지 실제로 동시에 실…","fields":{"slug":"/16/"},"frontmatter":{"date":"September 19, 2025","title":"병행성과 병렬성의 차이 및 프로세스 동기화의 필요성","tags":["운영체제"]},"rawMarkdownBody":"\n## 병행성(Concurrency)\n\n---\n\n![img.png](concurrency.png)\n\n\n병행성은 다른 말로 **동시성**이라고 부르는 용어입니다.\n이전까지 보았던 싱글 코어에서 프로세스를 처리하기 위해 많은 프로세스들을 **컨텍스트 스위칭**을 통해 효율적으로 프로세스를 처리했던것 기억할것 입니다.\n이경우 프로세스를 동시에 처리한다고 표현하지만 사실 이는 빠른 속도로 프로세스를 스위칭해서 실행시키는 것이지 실제로 동시에 실행되는 것은 아닙니다.\n\n동시성의 핵심 키워드는 **동시에 처리되게 보이는것**입니다.\n\n<br>\n<br>\n\n## 병렬성(Parallelism)\n\n---\n\n![img.png](parallelism.png)\n\n병렬 처리는 프로그램의 독립적인 작업을 동시에 실행할 수 있는 능력입니다. 이러한 작업은\n다른 프로세스 코어 단위에서, 혹은 분산 시스템 처럼 완전히 다른 컴퓨터에서 동시에 실행될 수 도 있습니다.\n\n병렬성의 핵심 키워드는 **실제로 동시에 처리되고 있는것**입니다.\n\n\n<br>\n<br>\n\n## 동기화\n\n---\n\n동시다발적으로 실행되는 프로세스들은 공동의 목적을 수행하기 위해 서로 협력하며 영향을 주고 받기도 합니다.\n조금 전 설명했던 **동시성**, **병렬성** 모두 동시다발적으로 수행되는 환경입니다.\n\n이런 환경의 예시를 하나들면, 워드 프로세스가 있습니다. 해당 프로세스는 글을 쓸수도 있고, 쓰여진 글을 읽을 수도 있고,\n맞춤법을 검사하는 기능도 있습니다. 하지만 해당 프로세스가 따로 동작하는 것이 아닌 모두 하나의 프로그램처럼 보여지고 있습니다.\n\n이런 상황을 **동시 다발적**이란 표현을 통해 하고, 이런 동시 다발적인 상황의 **수행 시기**를 맞춰주는 것이\n**동기화**라고 합니다.\n\n<br>\n\n### 수행 시기를 맞추다?\n\n이전에 설명한 **수행 시기**를 맞추다는 말은 추상적입니다.\n\n이를 두가지 관점으로 볼 수 있습니다.\n\n1. 실행 순서 제어: 프로세스를 올바른 순서대로 실행하는것\n2. 상호 배제: 동시에 접근해서는 안 되는 자원에 하나의 프로세스만 접근하는 것\n\n다시 말해 **동기화**는 실행 순서를 제어하는 **동기화**와, **상호 배제**를 위한 동기화가 있습니다.\n\n<br>\n<br>\n\n## 1. 실행 순서를 제어하는 동기화\n\n---\n\n![img.png](execution_order.png)\n\n실행 순서를 제어한다는 것은 요리 레시피 순서를 지키는것과 같습니다.\n재료를 준비하고, 손질하고, 요리하는 이런 일련의 과정을 지켜 보았을 때\n재료 손질이 준비보다 먼저일 수 없고, 요리또한 손질보다 먼저일 수 없습니다.\n\n프로세스도 마찬가지로 무언가를 읽게 하였는데 읽은 대상이 생성 되어있고, 작성되어있어야 합니다.\n이런 것을 **실행 순서**라고 표현하며 이것을 지키게 하는 것을 **동기화**라고 표현합니다.\n\n\n<br>\n<br>\n\n## 2. 상호 배제를 위한 동기화\n\n---\n\n**상호 배제**란 공유가 불가능한 자원의 동시 사용을 피하기 위해 사용하는 알고리즘입니다.\n여기서 말하는 공유가 불가능한 자원은 실제로 공유하면 안되는 자원이 아닌, 동시 사용하는 경우 문제가 발생하는\n자원입니다. \n\n아래 예시를 통해서 보면\n\n![img.png](mutual_exclusion.png)\n\n프로세스A는 현재 잔고에서 2만원을 더하고, 프로세스B는 현재 잔고에서 5만원을 더합니다.\n이러한 경우 총합 7만원을 더하는 형태가 될것입니다.\n\n하지만 프로세스A가 값을 더하고(12만원) 저장하기 전에 **콘텍스트 스위칭**이 일어난다면 다음 프로세스B는\n저장하기 전 값을 조회하고(10만원) 자신의 값을 저장할것 입니다(15만원).\n다시 프로세스 A로 돌아오면 12만원을 저장하고 프로세스 B로 돌아오면 15만원을 저장합니다.\n이과정에서 서로의 결과를 무시하는 방향으로 진행되고 최종적으로 마지막에 저장한 값은 다른 프로세스의 결과를\n반영하지 않는 상태가 됩니다.\n\n이런 상황은 동시에 사용하는 자원에 대해 **동기화**를 이루지 못해서 발생한 경우이고, 이 경우 **상호 배제를 위한 동기화**\n를 진행해야 합니다.\n\n<br>\n<br>\n\n## 출처\n\n---\n\n[동시성, 병렬성 출처](https://www.baeldung.com/cs/concurrency-vs-parallelism)\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n"},{"excerpt":"다단계 큐 스케쥴링(Multilevel queue scheduling) 멀티 레벨 스케줄링은 우선순위 스케줄링의 발전된 형태입니다.\n아래 그림을 통해 설명 하면,  이전에는 준비상태에 해당하는 단 하나의 큐만 사용하여 스케줄링을 진행하였는데,\n멀티레벨 스케줄링은 우선순위에 따른 n개의 큐를 이용하는 방식입니다. 가장 높은 우선순위에 있는 큐들을 처리하고,…","fields":{"slug":"/15/"},"frontmatter":{"date":"September 18, 2025","title":"멀티 레벨 큐와 멀티 레벨 피드백 큐 스케줄링","tags":["운영체제"]},"rawMarkdownBody":"\n## 다단계 큐 스케쥴링(Multilevel queue scheduling)\n\n---\n\n멀티 레벨 스케줄링은 **우선순위** 스케줄링의 발전된 형태입니다. \n아래 그림을 통해 설명 하면,\n\n<br>\n\n![img.png](multilevel_queue.png)\n\n<br>\n\n이전에는 준비상태에 해당하는 단 하나의 큐만 사용하여 스케줄링을 진행하였는데, \n멀티레벨 스케줄링은 우선순위에 따른 n개의 큐를 이용하는 방식입니다.\n\n가장 높은 우선순위에 있는 큐들을 처리하고, 가장 높은 우선순위 큐가 비게 된다면 그 아래 우선순위의 큐를 처리하게 됩니다.\n그림을 통해 이해하자면, 우선순위 0 -> 우선순위 1 -> 우선순위 2 이렇게 처리하게 되는것입니다.\n\n멀티레벨 큐의 특징으로는 각각의 큐들을 개별적으로 핸들링 할 수 있습니다.\n예를들어, 특정 큐의 타임 슬라이드와 다른 큐의 타임 슬라이드를 다르게 처리 한다던가, 혹은 스케줄링 방식 자체를\nFCFS를 적용하고 다른 곳에서는 라운드로빈을 적용하는것 처럼 개별적인 핸들링이 가능합니다.\n\n<br>\n<br>\n\n### 다단계 큐 스케쥴링 문제점\n\n---\n\n다단계 큐 스케줄링의 문제점으로는 **기아** 현상이 있습니다.\n\n멀티레벨 큐 방식에서는 큐간의 이동이 불가능합니다. 그렇기 떄문에 우선순위가 낮은 곳에 배정받은 프로세스들은\n이전에 보았던 **에이징**방식을 사용할수 없습니다. 그렇기 때문에 이러한 방식은 우선순위가 올때 까지 기다려야 하는\n기아 현상을 문제로 가지고 있습니다.\n\n이러한 방식의 해결법은 아래 설명할 다단계 피드백 큐 스케줄링으로 해결이 가능합니다.\n\n<br>\n<br>\n\n## 다단계 피드백 큐 스케줄링(multilevel feedback queue scheduling)\n\n---\n\n![img.png](multi_feedback_queue.png)\n\n<br>\n\n다단계 피드백 큐 스케줄링 같은경우는 프로세스들이 큐 사이로 이동할 수 있습니다. 그렇기 때문에 이전 방식에서 보았던\n**기아**현상을 직접적으로 해결할 수 있습니다.\n\n<br>\n\n### 다단계 피드백 큐 스케줄링 특징\n\n\n이러한 이동가능한 점 때문에 **멀티 레벨 큐**와 다른 점이 있습니다.\n**멀티 레벨 피드백 큐**는 처음 생성된 프로세스가 우선순위가 가장 높은 큐로 삽입이 됩니다. 그 이후 CPU를 할당받고\n타임슬라이드 동안 실행되며, 이 실행이 끝나게 된다면 다음 우선순위 큐로 넘어 갑니다(우선순위가 낮아짐). 또 다음 우선순위\n큐에서 실행이 끝나지 않는다면 또 다음 우선순위로 넘어가고 이 과정을 반복합니다.\n\n이렇게 우선순위가 낮아지는 방식을 사용함으로써 자동으로 **CPU 버스트**가 많은 프로세스는 우선순위가 낮아지고,\n**IO 버스트**가 많은 프로세스는 상대적으로 우선순위가 높아질것입니다.\n\n### 기아 해결\n\n또한, 프로세스들이 이동가능 하기 때문에 우선순위가 낮아져 **기아**상태에 빠진 프로세스에는 **에이징**기법을 적용해\n다시 우선순위를 높이게 됩니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"excerpt":"스케줄링 알고리즘 개요 스케줄링 알고리즘중 다섯가지의 알고리즘을 선점, 비선점을 통해 설명하겠습니다. 비선점 스케줄링 선입 선처리 스케줄링 (FCFS) 최단 작업 우선 스케줄링 (SJF) 선점 스케줄링 라운드 로빈 스케줄링 최소 잔여 시간 우성 스케줄링 (SRT) 우선순위 스케줄링 비 선점 스케줄링 선입 선처리 스케줄(FCFS)  FCFS는 준비 큐에 들…","fields":{"slug":"/14/"},"frontmatter":{"date":"September 17, 2025","title":"CPU 스케줄링 알고리즘 (FCFS, SJF, SRTF, 우선순위, 라운드 로빈)","tags":["운영체제"]},"rawMarkdownBody":"\n## 스케줄링 알고리즘 개요\n\n---\n\n스케줄링 알고리즘중 다섯가지의 알고리즘을 선점, 비선점을 통해 설명하겠습니다.\n\n<br>\n\n- 비선점 스케줄링\n  - 선입 선처리 스케줄링 (FCFS)\n  - 최단 작업 우선 스케줄링 (SJF)\n\n<br>\n\n- 선점 스케줄링\n  - 라운드 로빈 스케줄링\n  - 최소 잔여 시간 우성 스케줄링 (SRT)\n  - 우선순위 스케줄링\n\n<br>\n\n# 비 선점 스케줄링\n\n<br>\n<br>\n\n## 선입 선처리 스케줄(FCFS)\n\n---\n\n![img.png](fcfs.png)\n\n<br>\n\nFCFS는 **준비 큐**에 들어가있는 순서대로 CPU를 할당하는 간단한 스케줄링 입니다.\n\n하지만, FCFS 방식에는 **호위 효과**라는 문제가 있습니다.\n\n그림을 보면 프로세스 A, B, C순서대로 실행되며 각각 실행 시간이 17, 5, 2 ms가 걸리게 됩니다.\n이상황에서 프로세스 B는 실행 상태가 되기 위해 최소 17ms를 기다려야 하며, 프로세스 c는 22ms를 기다리게 됩니다.\n\n> 이러한 현상을 **호위 효과(Convoy effect)** 라고 하며 이것이 FCFS 스케줄링의 단점입니다.\n\n<br>\n<br>\n\n하지만, 이러한 FCFS 방식도 배치 처리 시스템이나 작업 길이가 거의 비슷하고 사용자와 상호 작용이 필요하지 않는 환경에는\n적합하며, 멀티프로그래밍이나 실시간 시스템에서는 부적합합니다.\n\n<br>\n<br>\n\n## 최단 작업 우선 스케줄링(SJF)\n\n---\n\n![img.png](sjf.png)\n\n<br>\n\n최단작업 우선 스케줄링(SJF)는 이전 FCFS방식에서 **호위 효과**를 억제하기 위해 사용하는 방식입니다.\n\n**호위 효과**는 실행시간이 긴 프로세스 때문에 다른 프로세스가 기다리는 시간이 길다는 문제가 있고,\n이러한 문제를 실행시간이 짧은 프로세스를 먼저 시행되게 하여 해결하는 방식입니다.\n\n그림을 통해 보면 FCFS방식의 평균 대기시간은 13ms인 반면에 SJF방식의 편균대기 시간은 3ms로 줄어든것을\n확인할 수 있습니다.\n\n> 즉 SJF방식은 호위효과를 줄여 프로세스들의 평균대기시간을 줄이는 방법으로 이해하면 됩니다.\n\n하지만, 이러한 방식도 문제가 있는데, 실행 시간이 긴 프로세스가 **기아**상태에 빠지기 쉽다는 것입니다.\n\n이러한 방식은 평균 대기 시간을 중요하게 여기는 시스템에 적합하며, 실시간 시스템이나 사용자 대화형 시스템에 부적합하게 됩니다.\n\n<br>\n<br>\n\n#  선점 스케줄링\n\n<br>\n<br>\n\n## 라운드 로빈 스케줄링\n\n---\n\n![img.png](round_robin.png)\n\n<br>\n\n라운드 로빈 스케줄링은 선입 선처리 방식(FCFS)방식에서 **타임 슬라이스**가 더해진 방식입니다.\n여기서 말하는 **타임 슬라이스**는 CPU를 사용할 수 있는 정해진 시간을 의미합니다.\n\n그림에서처럼 타임 슬라이스가 4ms이면 한번에 4ms까지 CPU를 할당받을 수 있고, 그 이후는 큐 가장 뒤로 들어가며\n콘텍스트 스위칭이 일어나게 됩니다.\n\n<br>\n\n> 라운드 로빈 방식의 중요한 포인트는 **슬라이스 크기**입니다.\n\n만약 슬라이스 크기가 지나치게 크다면 **FCFS**방식과 다를게 없을 것이고, 지나치게 작다면 콘텍스트 스위칭으로 인한\n오버헤드가 많이 발생할 것입니다.\n\n<br>\n<br>\n\n## 최소 잔여 시간 우선 스케줄링 (SRT)\n\n---\n\n![img.png](srt.png)\n\n<br>\n\n최단 작업 우선 알고리즘(SJF) 그리고 라운드 로빈 알고리즘을 합친 형태입니다.\n즉 작업 시간이 짧은 프로세스를 먼저 실행하되, 타임슬라이스 보다 큰 프로세스는 다시 큐 뒤로 보내고 작업을 이어가는 방식입니다.\n\n위 알고리즘은 특이한 점이 있어서 상세히 설명하겠습니다.\n\n<br>\n\n### SRT 동작 방식\n\n1. 새로운 프로세스가 도착하면 그 프로세스의 남은 실행 시간을 계산합니다\n2. 준비 큐에 있는 프로세스 중에서 현재 실행 중인 프로세스를 포함하여 가장 짧은 실행 시간을 가진 프로세스에 CPU를 할당합니다\n3. 만약 새로운 프로세스가 도착하고 현재 실행 중인 프로세스 보다 남은 실행 시간이 더 짧다면 현재 프로세스는 중단되고 CPU는 새 프로세스에 할당되는 '선점'이 발생합니다.\n4. 선점이 발생하면 운영체제는 콘텍스트 스위칭으로 CPU자원을 현재 프로세스에서 새 프로세스로 교체합니다.\n5. 선점된 프로세스는 준비 큐로 이동합니다.\n\n<br>\n\nSRT또한 SJF와 비슷한 장 단점을 공유하는데, 평균 대기 시간을 최소화 하는 장점을 가지지만, 작업 시간이 긴\n프로세스는 CPU 할당을 받기 어렵다는 단점이 있습니다.\n\n<br>\n<br>\n\n## 우선 순위 스케줄링\n\n---\n\n우선순위 스케줄링은 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행하는 알고리즘 입니다.\n만약 같은 우선순위가 있다면 선입 선처리로 처리 됩니다.\n\n이러한 우선순위 알고리즘 방식은 기아(Starvation) 현상을 동반하며 이는 에이징 방식으로 해결가능 하다고 이전 파트에서 설명했으니\n넘어가겠습니다.\n\n\n\n\n\n\n\n\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n\n[SRT 출처](https://devshovelinglife.tistory.com/977)\n\n\n\n\n\n\n"},{"excerpt":"선점형? 비선점형? 개요 CPU 스케줄링은 자원 선점 후 자원에 대한 권한이 뺏길 수 있냐 없냐에 따라 두가지로 나누게 됩니다. 여기서 자원을 사용하고 있음에도 외부에서 CPU 자원을 뺏는 방식과, 한번 점유한 CPU 자원을 끝가지 사용할 수 있는 방식이 있습니다. 선점형 스케줄링 선점의 사전적 정의는 '남보다 앞서서 차지함'이라는 뜻을 가지게 됩니다. …","fields":{"slug":"/13/"},"frontmatter":{"date":"September 16, 2025","title":"선점형과 비선점형 스케줄링의 차이 및 기아 상태와 해결 방법","tags":["운영체제"]},"rawMarkdownBody":"\n## 선점형? 비선점형? 개요\n\n---\n\n**CPU 스케줄링**은 자원 선점 후 자원에 대한 권한이 뺏길 수 있냐 없냐에 따라 두가지로 나누게 됩니다.\n\n여기서 자원을 사용하고 있음에도 외부에서 CPU 자원을 뺏는 방식과, 한번 점유한 CPU 자원을 끝가지 사용할 수 있는 방식이 있습니다.\n\n<br>\n<br>\n\n## 선점형 스케줄링\n\n---\n\n> 선점의 사전적 정의는 '남보다 앞서서 차지함'이라는 뜻을 가지게 됩니다.\n\n즉, 어떤 프로세스가 CPU라는 자원을 사용하고 있음에도 운영체제가 CPU를 사용중인 프로세스로부터 자원을 강제로 빼앗아 다른 프로세스에 할당할 수 있는\n스케줄링 방식을 의미합니다.\n\n다르게 표현한다면 어떠한 프로세스도 CPU를 독점할 수 없다는 말입니다.\n\n선점형의 예시중 하나는 지금까지 보았던, 특정 주기마다 CPU에 대한 할당 권한을 다른 프로세스에게 넘겨주는 방식이 있습니다.\n\n<br>\n\n![img.png](preemptive.png)\n\n<br>\n<br>\n\n## 비 선점형 스케줄링\n\n---\n\n비선점형 스케줄링이란 하나의 프로세스가 자원을 사용하고 있다면 그 프로세스가 종료되거나 \n스스로 대기 상태에 접어들기 전까진 다른 프로세스가 끼어들 수 없는 스케줄링입니다.\n\n다르게 표현한다면 특정 프로세스가 CPU를 사용하기 시작했다면 자원 사용을 독점할 수 있는 방식입니다.\n\n<br>\n\n![img.png](non_preemptive.png)\n\n<br>\n<br>\n\n## 선점, 비선점의 장 단점\n\n---\n\n대부분의 운영체제는 **선점형 스케줄링**를 사용중입니다. 그럼에도 **비선점형 스케줄링**를 사용하는 곳이 있는데 그것은 각자의 장 단점이 존재하기 때문입니다.\n\n<br>\n\n- 선점형 스케줄링 장점\n\n> 선점형 스케줄링은 어는 한 프로세스의 자원 독점을 막고 프로세스들에 골고루 자원을 분배 할 수 있다는 장점이 있습니다.\n\n<br>\n\n- 선점형 스케줄링 단점\n\n> 콘텍스트 스위칭이 빈번하기 떄문에 오버헤드가 많이 발생합니다.\n\n<br>\n<br>\n\n- 비 선점형 스케줄링 장점\n\n> 상대적으로 선점형 보다 콘텍스트 스위칭에 대한 오버헤드가 작게 발생합니다.\n\n<br>\n\n- 선점형 스케줄링 단점\n\n> 하나의 프로세스가 작업이 끝나기를 기다려야 하기 때문에, 모든 프로세스가 골고루 자원을 사용할 수 없습니다.\n\n\n<br>\n<br>\n\n## 기아 상태(Starvation)\n\n---\n\n기아 상태란 우선순위가 밀린 프로세스가 영원히 자신의 우선순위까지 순서가 오지 못해 실행되지 못하는 상태를 기아 상태라고 합니다.\n\n<br>\n<br>\n\n## 기아 상태 해결법\n\n---\n\n이러한 기아 상태를 해결하기 위한 방법으로는\n\n**에이징** 기법을 활용하는 것입니다.\n\n기아 상태가 발생하는 이유는 항상 자신보다 높은 우선순위를 가지는 프로세스가 존재하기 떄문입니다.\n\n**에이징** 기법은 준비큐에서 대기가 길어진 프로세스들에게 우선순위를 조금씩 높여주는 방식을 사용합니다.\n결국 조금씩 우선순위가 높아진다면 언젠가는 해당 프로세스가 실행될 수 있게 됩니다.\n\n"},{"excerpt":"CPU 할당? 지금까지 배운 내용을 토대로 프로세스는 CPU를 필요로 하며, 프로세스가 실행 된다는 말은 메모리에 올라간 데이터를 토대로 프로세스가 CPU를 할당받아 사용\n하는것을 프로세스가 실행 된다고 표현합니다. 그 과정에서 프로세스는 일정 주기마다 컨텍스트 스위칭을 통해 CPU 할당을 바꾸고 IO요청에 대해서도 대기 상태로 들어가는 등\nCPU사용에 …","fields":{"slug":"/12/"},"frontmatter":{"date":"September 15, 2025","title":"CPU 스케줄링의 목적과 스케줄러의 종류","tags":["운영체제"]},"rawMarkdownBody":"\n## CPU 할당?\n\n---\n\n지금까지 배운 내용을 토대로 프로세스는 CPU를 필요로 하며, 프로세스가 실행 된다는 말은 메모리에 올라간 데이터를 토대로 프로세스가 CPU를 할당받아 사용\n하는것을 프로세스가 실행 된다고 표현합니다. 그 과정에서 프로세스는 일정 주기마다 컨텍스트 스위칭을 통해 CPU 할당을 바꾸고 IO요청에 대해서도 대기 상태로 들어가는 등\nCPU사용에 여러 변수가 있습니다.\n\n한가지 의문점은, 누가? 어떻게? CPU를 할당하는지 배운적은 없습니다.\n여기서 CPU라는 리소스에 대한 사용을 결정짓는건 운영체제입니다.\n그리고 오늘 글의 주제인 CPU 스케줄링은 운영체제가 CPU라는 자원을 배분하는 행위를 지칭합니다.\n\n<br>\n<br>\n\n## CPU 스케줄링 우선순위\n\n---\n\n![img.png](priority.png)\n\n운영체제는 많은 프로세스에게 공정하게 CPU라는 공용자원을 배분하기 위해 고려해야 하는것이 우선순위 입니다.\n우선순위라는 기준을 매겨야 하는 이유는\n운영체제는 어떤 프로세스는 당장 처리해야 할 중요성을 띄거나, IO작업이 많거나, CPU 사용시간 자체가 길거나처럼 각자의 사정이 있고, 이 사정 가운대 효율적으로 자원을 배분해야 하기 떄문입니다. \n\n<br>\n\n'우선순위가 높다'라는 표현은 CPU 사용에 우선권을 가집니다. 즉 먼저 처리되어야 한다 라는 뜻입니다.\n대표적으로 우선순위가 높은 프로세스는 입출력이 많은 프로세스 입니다.\n(입출력 처리가 많은 프로세스가 우선순위가 높은 이유는 아래에서 설명합니다.)\n\n대부분의 프로세스는 I/O 작업과 CPU처리를 번갈아가면서 수행하게 됩니다. 이 말은 프로세스 상태 변화에서 실행, 대기를 번갈아 가면서 사용한다는 뜻입니다.\n그렇지만 모든 프로세스가 동일한 비율로 I/O와 CPU처리를 하는것은 아닙니다. 여기서 CPU작업의 비율이 많다면 **CPU 집중 프로세스**라고 하게 되며, 반대로 I/O작업의\n비율이 많다면 **입출력 집중 프로세스** 라고 부르게 됩니다.\n\nCPU집중 프로세스는 실행상태가 많고, 입출력 집중 프로세스는 대기 상태가 많으니 입출력 집중 프로세스를 빠르게 대기 상태로 넘겨주는 것이 CPU사용에 대해서 더 효율적인\n방법일것입니다. 그렇기 떄문에 입출력 처리가 많은 프로세스가 우선순위가 높습니다.\n\n여담으로, CPU를 이용하는 작업을 **CPU 버스트**, 입출력을 이용하는 작업을 **입출력 버스트**라고 부르게 됩니다.\n\n<br>\n<br>\n\n이러한 우선순위는 **PCB**에 기록됩니다. **PCB** 우선순위 기준으로 먼저 처리할 프로세스를 결정하고 처리하게 됩니다.\n\n<br>\n<br>\n\n## 스케줄링 큐\n\n---\n\n![img.png](queue_scheduling.png)\n\n우선순위는 **PCB**에 기록되지만, 운영체제가 매 CPU 할당 과정마다 **PCB**를 확인하고 결정하는건 비효율 적인 방식입니다.\n그렇기 때문에 프로세스는 마치 '줄을 서는것'처럼 대기하게 됩니다. 이것을 **스케줄링 큐**라고 부르게 됩니다.\n\n<br>\n\n![img.png](ready_queue.png)\n\n<br>\n\n운영체제는 메모리로 적재되고 싶은 프로세스들을 큐에 삽입하여 줄을 세우고, CPU를 사용하고 싶거나, 특정 입출력장치를 사용하거 싶은 프로세스들을 줄세웁니다.\n이 과정에서 사용할 자원에 따라 다른 큐에서 대기하게 됩니다.\n\n운영체제가 관리하는 큐로는 **준비큐**와 **대기큐**로 이루어 져 있습니다. **준비 큐**는 말그대로 CPU를 이용하고 싶은 프로세스들이 대기하게 되고,\n\n<br>\n\n![img.png](wait_queue.png)\n\n<br>\n\n**대기 큐**는\n입출력장치를 이용하기 위한 대기 상태에 돌입한 프로세스들이 서는 줄입니다.\n큐에 들어와 있다고 해도 항상 순서대로 작동하는 것은 아니고 **우선 순위**를 고려합니다.\n\n<br>\n\n## 출처\n\n---\n\n[이미지 출처](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)\n"},{"excerpt":"동시성 이슈란?  동시성 이슈란 하나의 자원에 대해 여러 스레드가 접근할때 발생합니다. 예를 들어, 좋아요가 10 인 자원에 대해 스레드 a와 b가 동시에 접근해서 좋아요 10에 대한 값을 가져옵니다.\n스레드 a는 좋아요 카운트를 하나 늘리는 행위를 하고 스레드 b는 좋아요 카운트를 하나 줄이는 행위를 할때\n스레드 a가 좋아요 카운트를 늘리면 11가 됩니…","fields":{"slug":"/11/"},"frontmatter":{"date":"September 14, 2025","title":"멀티 쓰레드 프로그래밍의 동시성 이슈와 Thread-Safe 설계 방법","tags":["운영체제"]},"rawMarkdownBody":"\n\n## 동시성 이슈란?\n\n---\n\n<br>\n\n![img.png](concurrency.png)\n\n<br>\n\n동시성 이슈란 하나의 자원에 대해 여러 스레드가 접근할때 발생합니다.\n\n예를 들어, 좋아요가 10 인 자원에 대해 스레드 a와 b가 동시에 접근해서 좋아요 10에 대한 값을 가져옵니다.\n스레드 a는 좋아요 카운트를 하나 늘리는 행위를 하고 스레드 b는 좋아요 카운트를 하나 줄이는 행위를 할때\n스레드 a가 좋아요 카운트를 늘리면 11가 됩니다. 하지만 스레드 a와 b는 좋아요 카운트에 동시에 접근해서 초기값 10을 받은 상태라면\n스레드 b는 늘어난 11라는 숫자대신 10을 기준으로 값을 줄이게 됩니다. 그럼 최종 결과는 10이 아닌 9라는 값으로 나오게 됩니다.\n\n이처럼 멀티 스레드 환경에서는 하나의 자원에 동시에 접근하게 되면 이러한 문제가 발생할 수 있습니다.\n\n<br>\n<br>\n\n## 스레드 안전\n\n---\n\n그럼 우리가 추구해야 할 문제는 스레드 안전한 멀티 스레드 프로그래밍을 구현할 수 있어야 한다. 이것을 구현하는\n방법에 대해 이야기 하려고 합니다.\n\n<br>\n<br>\n\n## 스레드 안전 여부 판단\n\n---\n\n1. 전역 변수나 힙, 파일과 같이 여러 스레드가 동시 접근 가능한 자원을 사용하는가\n2. 핸들과 포인터를 통한 데이터의 간접 접근이 가능한가?\n3. 부수 효과를 가져오는 코드가 있는가?\n\n<br>\n<br>\n\n## 스레드 안전을 지키기 위한 4가지 방법\n\n---\n\n1. 상호 배제(Mutual Exclusion)\n\n<br>\n\n- 공유 자원에 하나의 Thread만 접근할 수 있도록 세마포어/ 뮤텍스락을 통제하는 방법입니다.\n\n<br>\n\n2. 원자 연산(Atomic Operation)\n\n<br>\n\n- 공유 자원에 접근할 때 원자 연산을 이용하거나 원자적으로 정의된 접근 방법을 사용함으로써 상호 배제를 구현하는 방법입니다.\n- Atomic\n  - 공유 자원 변경에 필요한 연산을 원자적으로 분리한 뒤에 실제로 데이터의 변경이 이루어지는 시점에 Lock을 걸고, \n  데이터를 변경하는 시간 동안 다른 쓰레드의 접근이 불가능하도록 하는 방법입니다.\n\n<br>\n\n3. Thread-Local Storage (스레드 지역 저장소)\n\n<br>\n\n- 공유 자원의 사용을 최대한 줄이고 각가의 쓰레드에서만 접근 가능한 저장소들을 사용함으로써 동시 접근을 막는 방법입니다.\n- 일반적으로 공유 상태를 피할 수 없을 때 사용하는 방식이며, 전역 변수 사용을 자제하라는 뜻으로 생각하면 됩니다.\n\n<br>\n\n4. Re-entrancy (재진입성)\n\n<br>\n\n- 쓰레드 호출과 상관 없이 프로그램에 문제가 없도록 작성하는 방법입니다.\n- 어떤 함수가 한 스레드에 의해 호출되어 실행 중이라면 다른 스레드가 그 함수를 호출하더라도 그 결과가 각각에게 옳바르게 주어져야 합니다.\n- 쓰레드끼리 독립적으로 동작할 수 있도록 코드를 작성하는 것으로 생각하면 됩니다.\n\n<br>\n<br>\n\n\n\n\n"},{"excerpt":"멀티 프로세스는 운영체제에서 하나의 응용 프로그램에 대해 동시에 여러 개의 프로세스를 실행할 수 있게 하는 기술입니다.\n보통은 하나의 프로그램을 실행하기 위해서 하나의 프로세스만 메모리에 생성하게 되지만, 부가적인 기능을 위해\n여러개의 프로세스를 생성하는 것입니다. 어떻게 멀티 프로세스를 생성할까? 멀티 프로세스는 이전에 보았던 계층구조 프로세스 처럼 부…","fields":{"slug":"/10/"},"frontmatter":{"date":"September 13, 2025","title":"멀티 프로세스와 멀티 쓰레드의 차이 및 장단점","tags":["운영체제"]},"rawMarkdownBody":"\n![img.png](multi_process.png)\n\n멀티 프로세스는 운영체제에서 하나의 응용 프로그램에 대해 동시에 여러 개의 프로세스를 실행할 수 있게 하는 기술입니다.\n보통은 하나의 프로그램을 실행하기 위해서 하나의 프로세스만 메모리에 생성하게 되지만, 부가적인 기능을 위해\n여러개의 프로세스를 생성하는 것입니다.\n\n<br>\n<br>\n\n### 어떻게 멀티 프로세스를 생성할까?\n\n멀티 프로세스는 이전에 보았던 계층구조 프로세스 처럼 부모 프로세스가\n여러개의 자식 프로세스를 생성합니다.\n\n부모 프로세스는 자식 프로세스의 PID를 알고있으며 자식또한 PID와 PPID를 알고있어\n서로 통신이 가능합니다.\n\n이런 성질은 각각 독립적이지만 통신이 가능하게 만들었고 멀티 프로세스의 대표적인 예가\n브라우저의 탭이라고 할 수 있습니다.\n\n브라우저 탭은 문제가 발생해서 닫아야 하는 상황이여도 다른 탭까지 닫히지 않고 개별적으로\n운용을 할 수 있는걸 기억해보면 독립적이란 말을 더 잘 이해할 수 있을것이다.\n\n<br>\n<br>\n\n## 멀티 프로세스의 장점\n\n<br>\n\n1. 안정성\n\n멀티 프로세스의 안정성은 각각의 프로세스가 독립적이기 떄문에 가능합니다.\n대표적인 예로 좀전에 설명을 했던 특정 브라우저 탭이 문제가 발생하여 닫아야 하는 상황에서\n같은 브라우저의 다른 탭까지 닫히지는 않습니다.\n이런것이 독립적인 성격에 의한 안정성이라고 할 수 있습니다.\n\n<br>\n<br>\n\n## 멀티 프로세스의 단점\n\n<br>\n\n1. 문맥교환 (Context Switching) Overhead\n\n멀티 태스킹을 이루는 기술인 문맥 교환 과정에서 성능 저하가 발생할 수 있습니다.\n프로세스를 컨텍스트 스위칭 하면, CPU는 다음 프로세스의 정보를 불러오기 위해\n메모리를 검색하고, CPU 캐시 메모리를 초기화하며, 프로세스 상태를 저장하고, \n불러올 데이터를 준비해야 하기 떄문에, 빈번한 문맥교환이 발생하고 이 비용은 곧 오버헤드로 발생할 수 있습니다.\n\n<br>\n<br>\n\n2. 자원 공유 비효율성\n\n프로세스는 독립적인 메모리를 가지고, 멀티 프로세스는 독립적인 메모리 공간의 합일 것입니다.\n그렇기 때문에 메모리 비효율성을 초래합니다.\n\n<br>\n<br>\n\n## 멀티 스레드\n\n---\n\n![img.png](multi_thread.png)\n\n<br>\n\n이전에 보았던 것처럼 스레드는 하나의 프로세스 내에 있는 실행 흐름입니다.\n멀티 스레드는 하나의 프로세스 안에 여러개의 실행흐름을 가지는 것입니다.\n멀티 스레드 또한 멀티 프로세스 처럼 여러개의 작업을 동시 실행 할 수 있습니다.\n\n이전에 보았던 것처럼 멀티 프로세스는 브라우저의 여러개의 탭을 통해 예시를 들었습니다.\n하지만, 멀티 스레드는 같은 브라우저라 할지라도 동일탭에 여러 실행 흐름을 말하게 되고 \n예를들어 네트워크 처리 스레드, 검색 스레드 와 같이 동일한 프로세스 내 기능들을 말하게 됩니다.\n\n<br>\n<br>\n\n## 멀티 스레드의 장점\n\n---\n\n### 프로세스보다 스레드가 가벼움\n\n스레드는 프로세스보다 용량이 가볍다. 이유는 데이터, 코드, 힙 영역을\n프로세스와 공유해서 사용하기 때문에 내장된 정보다 프로세스보다 작기 떄문입니다.\n그렇기 때문에 스레드를 제거하는 작업이 프로세스를 제거하는 작업보다 가볍습니다.\n\n<br>\n<br>\n\n### 자원의 효율성\n\n멀티 스레드는 하나의 프로세스 내에서 스택영역을 제외한 영역을 공유하기 때문에\n프로세스 간 통신을 사용하지 않고도 자원의 공유가 가능하여 자원을 효율적으로 사용할 수 있습니다.\n\n<br>\n<br>\n\n### Context Switching 비용 감소\n\n스레드 문맥 교환 또한 오버헤드가 존재하지만, 프로세스 문맥교환과 비교했을 때,\n상대적으로 오버헤드가 적습니다.\n\n이유는 프로세스 컨텍스트 스위칭 비용은 스위칭할 때마다 CPU 캐시에 있는 내용을 모두 초기화하고,\n새로운 프로세스 정보를 CPU 캐시에 적재해야 하기 떄문입니다.\n하지만, 스레드 문맥교환은 스레드 개별적인 정보만 교체하면 되기 떄문에 비용이 상대적으로 낮습니다.\n\n<br>\n<br>\n\n## 멀티 스레드의 단점\n\n멀티 프로세스는 개별적인 작업으로 인해 독집적이고, 각자의 문제를 전파하지 않는다고 합니다.\n\n하지만, 멀티 스레드는 하나의 스레드가 문제가 발생하면 다른 스레드들고 영향을 받아 전체가 종료가 될 수 있습니다.\n\n<br>\n<br>\n\n## 데드락\n\n데드락이란 하나의 자원을 사용하기위해 여러 곳에서 접근했고, 그상황에서 교착상태가 일어났을때\n여러대의 스레드가 서로 대기하면서 무한정 기다리는 현상을 데드락이라고 합니다.\n\n예를들어, 스레드 1 은 자원 A을 점유하고 있는 상태에서 자원 B가 필요한 상황입니다. \n그리고 스레드 2 는 자원 B를 점유하고 있는 상태에서 자원 A이 필요한 상황입니다. \n하지만 스레드 1은 자원 B가 필요한 상황에서 자원 A을 빌려줄 수 있는 상황이 아니고, \n스레드 2또한 자원 A이 필요한 상태에서 자원 B를 빌려줄 수 없는 상황인 것입니다.\n이처럼 다수의 쓰레드가 같은 lock을 동시에, \n다른 명령에 의해 획득하려 할 때 서로 절대 불가능한 일을 계속적으로 기다리는 상황을 이야기 합니다.\n\n\n\n"},{"excerpt":"기아 상태와 CPU 스케줄링 프로세스들은 실행할 때 컴퓨터 자원을 사용하는데, 이때 CPU도 사용합니다.\n그런데 만약 하나의 프로세스가 오랜 시간 동안 CPU를 점유하거나,\n너무 짧은 텀동안만 실행되는 경우 공정하지 못한 방법으로 자원을 할당하게 될 것이고\n이는 시스템의 효율적이지 못한 방법으로 돌아가게 하는 길을 초래할 수 있을 겁니다.\n이를 컴퓨팅에서…","fields":{"slug":"/5/"},"frontmatter":{"date":"September 12, 2025","title":"5. CPU 스케줄링","tags":["운영체제"]},"rawMarkdownBody":"\n## 기아 상태와 CPU 스케줄링\n\n프로세스들은 실행할 때 컴퓨터 자원을 사용하는데, 이때 CPU도 사용합니다.\n그런데 만약 하나의 프로세스가 오랜 시간 동안 CPU를 점유하거나, \n너무 짧은 텀동안만 실행되는 경우 공정하지 못한 방법으로 자원을 할당하게 될 것이고\n이는 시스템의 효율적이지 못한 방법으로 돌아가게 하는 길을 초래할 수 있을 겁니다.\n이를 컴퓨팅에서는 기아 현상이라고 하는데,\n이로 인해 프로세스들에게 CPU 자원 할당을 배분해주는 CPU 스케줄링이 개발되었고,\n운영체제에 반드시 필요로 하게 되었습니다.\n\n> 기아 현상에 대한 대표적인 해결 방법은 에이징 기법을 이용하는 것입니다.\n> 오랫동안 대기한 프로세스의 우선순위에 대해 가중치를 주어,\n> 처음에 우선순위가 낮아도 언젠가는 우선순위가 높아져 기아 현상을 막을 수 있습니다.\n> 이와 같이 CPU 스케줄링에서는 이러한 문제 해결을 위한 다양한 방식들이 있습니다. \n\n## 프로세스 우선 순위\n\n스케줄링을 지정하는 것은 순서를 지정하는 것과 같습니다.\n그런데 어떻게 프로세스들 간의 순위를 공정하게 지원하고 있을까요?\n\n### 순차방식\n\n가장 단순하게 생각해보면 요청이 들어온 순서대로 할당하는 방식입니다.\n그러나 이 방식은 빨리 처리해야 하는 프로세스가 있을 수 있는 상황에서 대응하지 못한다는 것입니다.\n\n예시로 CPU를 많이 사용하는 프로세스가 I/O 작업을 하는 프로세스 보다 늦게 들어올 경우,\n순서상으로는 뒤에 있어야 하지만, CPU 자원을 할당한다는 측면에서 볼 떄에는 앞 순위로 두는 것이 효울적일 것입니다.\n\n### 우선순위 지정 방식\n\n위 순차적인 방식이 아닌, 별도의 우선순위를 지정하는 방식도 있습니다.\n이때, 우선순위에 대한 정보는 PCB에 저장이 됩니다.\n\n이로 인해 프로세스의 중요도에 맞게 프로세스가 CPU를 이용할 수 있도록 운영체제가 부여하는 것이 우선순위이며,\n운영체제는 PCB를 기반으로 어떤 프로세스가 CPU를 얼마나 사용하게 될 것인지 등을 결정합니다.\n \n프로세스 우선순위는 간단한 명령어나 프로그램 등으로 확인이 가능한데, \n일부 우선순위의 경우에는 사용자가 직접 설정 가능한 것도 있습니다. \n\n### 스케줄링 큐\n\n프로세스가 여러 개일 경우, 다음 CPU 자원을 이용할 프로세스를 선택하기 위해 매번 모든 프로세스들의 PCB를 다 뒤져보는 것은 매우 비효율적일 것입니다.\n또한, CPU 말고도, 메모리, 입출력 장치를 사용하고자 하는 경우에도 비슷한 상황을 겪을 것입니다.\n\n때문에 운영체제는 어떤 자원을 이용하고자 할 때 대기 하는 스케줄링 큐를 활용하고 있습니다.\n\n이때, 큐라고 해서 반드시 선입선출(FIFO)에 국한되지 않습니다.\n\n## 선점형 스케줄링과 비선점형 스케줄링\n\n스케줄링 방식에는 선점형 스케줄링과 비선점형 스케줄링 방식이 있습니다.\n\n### 선점형 스케줄링\n\n선점형 스케줄링은 현재 CPU를 사용 중인 프로세스로부터 CPU 자원을 뺴앗아 요청한 프로세스에 할당하는 방법입니다.\n어느 한 프로세스의 자원 독점을 막고 프로세스에 골고루 자원을 배분할 수 있으나, 그 만큼 컨텍스트 스위칭 과정에서 오버헤드가 발생할 수 있습니다.\n\n### 비선점형 스케줄링\n\n비선점형 스케줄링은 현재 CPU를 사용 중인 프로세스의 작업이 끝날 때까지 기다리는 방식입니다.\n\n선점형 스케줄링과 반대되는 개념으로, 컨텍스트 스위칭에서 발생하는 오버헤드가 적지만, 한편으로는 모든 프로세스가 골고루 자원을 이용하기 어렵습니다.\n\n## CPU 스케줄링 알고리즘\n\n선점형 스케줄링과 비선점형 스케줄링을 기반으로 다양한 CPU 스케줄링 알고리즘이 있습니다. \n\n### 선입 선처리 스케줄링\n\nFCFS(First Come First Served) 스케줄링으로, 준비 큐에 삽입된 순서대로 처리하는 비선점 스케줄링 방식입니다.\nCPU를 먼저 요청한 프로세스부터 CPU를 할당합니다.\n이로 인해 프로세스들이 기다리는 시간이 매우 길어질 수 있는 부작용이 있으며,\n이를 convoy effect, 호위 효과라고 합니다.\n\n### 최단 작업 우선 스케줄링\n\nSJF(Shortest Job First) 스케줄링으로,\n사용 시간이 긴 프로세스를 나중에 실행하고, \n시간이 짧은 프로세스를 먼저 실행함으로써 평균 대기 시간을 줄일 수 있습니다.\n이 알고리즘은 기본적으로는 비선점형 스케줄링 방식에 속하지만,\n선점형과 비선점형 스케줄링 방식으로 모두 가능합니다.\n\n### 라운드 로빈 스케줄링\n\nRR(Round Robin) 스케줄링으로, \n선입 선처리 스케줄링과 시분할 시스템의 타임 슬라이스(time slice) 개념이 결합된 방식입니디.\n정해진 타임 슬라이스만큼의 시간 동안 돌아가며 CPU를 이용하게 하는 선점형 스케줄링입니다.\n\n### 최소 잔여 시간 우선 스케줄링\n\nSRT(Shortest Remaining Time) 스케줄링으로,\n최단 작업 우선 스케줄링과 라운드 로빈 스케줄링이 결합된 형태입니다.\n정해진 시간만큼 CPU를 이용하되, \n다음으로 CPU를 사용할 프로세스로는 남은 작업 시간이 가장 적은 프로세스를 선택합니다.\n\n### 우선순위 스케줄링\n\n프로세스들에 우선순위를 부여하고, 우선순위가 높은 프로세스부터 실행하는 방식입니다.\n우선순위가 같은 프로세스들은 선입 선처리 스케줄링으로 돌아가고,\n최단 작업 우선 스케줄링이나 최소 잔여 시간 스케줄링은 포괄적인 의미에서 우선순위 스케줄링에 속한다고 할 수 있습니다.\n\n### 다단계 큐 스케줄링\n\n멀티 레벨 큐 스케줄링으로도 불리는데, 우선순위 스케줄링의 발전된 형태입니다.\n우선순위 별로 준비 큐를 여러 개 사용하고, 우선순위가 높은 큐에 있는 프로세스를 먼저 실행합니다.\n우선순위가 높은 큐가 비어 있다면, 그 다음 우선순위 큐에 있는 프로세스를 처리합니다.\n이러한 방식은 프로세스 유형별로 우선순위를 구별하게 하여 관리가 쉬워집니다.\n큐 별로 타임 슬라이스를 여러 개 지정할 수도 있고, 큐마다 다른 스케줄링 알고리즘을 사용할 수도 있습니다.\n기본적으로 큐 간 이동이 불가능하기 때문에, 우선순위가 낮은 프로세스는 계속해서 우선순위가 낮을 수 밖에 없고,\n그로 인해 기아 현상을 겪을 수도 있습니다.\n\n### 다단계 피드백 큐 스케줄링\n\n멀티 레벨 피드백 큐 스케줄링으로도 불리는 이 방식은 다단계 큐 스케줄링의 발전된 형태로,\n큐 간 이동이 가능합니다.\n새로 준비 상태로 된 프로세스가 있으면 가장 우선순위가 높은 큐에 삽입합니다.\n일정 시간 즉, 타임 슬라이스 만큼 CPU를 사용할 수 있는데,\n만약 작업이 끝나지 않았다면,\n그때 우선순위가 다음으로 높은 곳에 삽입을 합니다.\n작업을 많이 있는 프로세스일수록 우선순위가 점점 낮아지게 되고,\n따라서 CPU 집중 프로세스는 상대적으로 우선순위가 낮아지고, 입출력 집중 프로세스는 높아지게 될 겁니다.\n일정 시간 이상 낮은 우선순위에서 기다리고 있던 프로세스가 있었다면 이 프로세스의 우선순위를 점차 높임으로써 기아 현상을 방지할 수 있습니다.\n다단계 피드백 큐 스케줄링은 CPU 사용 시간이 길면 우선순위가 점점 낮아지고, 동시에 어떤 프로세스가 낮은 우선순위 큐에서 너무 오래 기다리면 우선순위를 높일 수도 있습니다.\n다단계 피드백 큐 스케줄링은 복잡하지만, CPU 스케줄링의 가장 일반적인 형태로 알려져 있습니다.\n"},{"excerpt":"스레드란?  스레드는 프로세스를 구성하는 실행의 흐름 단위라고 표현합니다. 또한, 하나의 프로세스가 복수적인 스레드를 가질 수 있습니다. 그렇기 때문에 스레드를 이용하면\n하나의 프로세스에서 여러 부분을 동시에 실행할 수 있습니다. 마치 화상 회의를 진행중에 회의 어플리케이션이란 프로세스 속 채팅과 화상통화의 기능이 독립적으로 돌아가는것과\n같이 여러 기능을…","fields":{"slug":"/9/"},"frontmatter":{"date":"September 12, 2025","title":"쓰레드의 개념, 메모리 공유 구조 및 TCB","tags":["운영체제"]},"rawMarkdownBody":"\n## 스레드란?\n\n---\n\n![img.png](thread.png)\n\n<br>\n\n스레드는 프로세스를 구성하는 실행의 흐름 단위라고 표현합니다.\n\n또한, 하나의 프로세스가 복수적인 스레드를 가질 수 있습니다. 그렇기 때문에 스레드를 이용하면\n하나의 프로세스에서 여러 부분을 동시에 실행할 수 있습니다.\n\n마치 화상 회의를 진행중에 회의 어플리케이션이란 프로세스 속 채팅과 화상통화의 기능이 독립적으로 돌아가는것과\n같이 여러 기능을 수행할 수 있습니다.\n\n<br>\n\n### 프로세스와 스레드\n\n---\n\n스레드를 이해하기 위해서는 프로세스와 엮어서 설명하고자 합니다.\n전통적인 CPU는 하나의 프로세스만 처리할 수 있었습니다. 메모장, 워드, 게임등 많은 프로세스가 하나의 실행\n흐름을 가지고 한 번의 하나의 부분만 실행되는 프로세스입니다.\n\n![img.png](single_process.png)\n\n이런 프로세스를 단일 스레드 프로세스라고 부릅니다.\n\n<br>\n\n하지만, 스레드라는 개념이 도입되면서 하나의 프로세스가 한 번에 여러가지 일을 동시에 처리하는 것이 가능해졌습니다.\n프로세스를 구성하는 명령어를 동시에 처리하는것이 가능해졌습니다.\n\n![img.png](multi_thread_process.png)\n\n<br>\n\n그림을 통해 스레드를 보게 되면 스레드는 '프로세스를 구성하는 실행의 흐름 단위'라고 표현 가능 할 것입니다.\n\n왜냐하면, 하나의 프로세스 안에 여러가지 스레드가 있고 각각의 작업 흐름을 가지며 프로세스가 하는 일을 병렬적으로 만들어\n주기 때문입니다.\n\n<br>\n<br>\n\n## 스레드 메모리 구조\n\n---\n\n![img.png](memory_model.png)\n\n스레드의 메모리 구조를 이해하기 위해서는 이전 프로세서의 구조를 상기해봐야 합니다.\n\n프로세스는 스택, 힙, 데이터, 코드 영역을 각자 가진다고 합니다.\n스레드는 '프로세스를 구성하는 실행 흐름의 단위'라고 했고, 이 떄문에 스레드는 프로세스의 메모리 구조의 대부분을 공유해서\n사용한다. 그렇기 때문에 여러 스레드의 작업이 하나의 프로세스 안에서 이루어져도 동시작업이 가능한 이유입니다.\n\n<br>\n\n그렇다면 어떻게 스레드는 프로세스와 스레드간 데이터를 공유하는 것일까?\n아래 그림을 통해서 보게되면\n\n<br>\n\n![img.png](thread_resource.png)\n[사진출처](https://gmlwjd9405.github.io/2017/10/01/basic-concepts-of-development-os.html)\n\n<br>\n\n우선 하나의 프로세스안에 코드, 데이터, 힙, 스택 영역이 존재합니다. 그리고 프로세스 내부의 개별적인 스레드가 존재합니다.\n\n스레드가 레지스터, 프로그램 카운터, 스택을 개별적으로 가지는 핵심 이유는 독립적인 실행 흐름을 보장하기 위해서입니다.\n\n프로그램 카운터는 각 스레드가 서로 다른 코드 위치에서 실행될 수 있도록 현재 실행 지점을 개별 추적하고, \n\n레지스터는 각 스레드의 작업 데이터를 독립적으로 저장합니다. \n이를 통해 CPU가 스레드 간 전환할 때 현재 상태를 저장하고 복원하여 중단된 지점에서 정확히 재개할 수 있습니다.\n스택 영역을 따로 가지는 이유는 각 스레드가 독립적인 함수 호출 흐름을 가져야 하기 때문입니다. \n\n스택은 함수 호출 시 지역 변수, 매개변수, 리턴 주소를 저장하는데, 만약 스레드들이 스택을 공유한다면 한 스레드의 \n함수 호출이 다른 스레드의 함수 실행에 영향을 주어 실행 흐름이 꼬이게 됩니다. 따라서 각 스레드는 독립적인 스택을 가져 서로 다른 함수를 안전하게 호출하고 실행할 수 있습니다.\n결과적으로 이런 구조를 통해 스레드들은 힙과 데이터 영역은 공유하면서도 각자 독립적인 실행 흐름을 유지할 수 있어\n, 하나의 프로세스 내에서 여러 작업을 동시에 효율적으로 처리할 수 있게 됩니다.\n\n<br>\n<br>\n\n## TCB란\n\n---\n\n![img.png](TCB.png)\n\n스레드 제어 블록은 운영체제가 각 스레드를 관리하기 위해 유지하는 데이터 구조체입니다. \n프로세스 제어 블록(PCB)과 유사하지만 스레드 수준에서 필요한 정보들을 담고 있습니다.\n링크드 리스트 형태로 구현되어 PCB안에 해당 스레드의 TCB를 내포하고 있는 형태로 저장됩니다.\n\n<br>\n\n![img.png](TCB2.png)\n\n\n\n![img.png](TCB3.png)\n\n\n<br>\n<br>\n\nTCB는 사진과 같은 형태로 저장되며, 아래와 같은 정보를 가진다.\n\n| 정보         | 설명                              |\n|------------|---------------------------------|\n| 스레드 식별자    | 각 스레드를 식별하는 고유한 식별자             |\n| 스레드 상태     | 실행 준비 대기 등 스레드의 현재 상태           |\n| 프로그램 카운터   | 스레드가 다음에 실행할 명령어의 주소            |\n| 레지스터       | 스레드가 현재 사용하고 있는 CPU 레지스터의 값을 저장 |\n| 스레드 우선순위   | 스케줄링 결정에 사용되는 스레드의 우선순위         |\n| 스레드 스택 포인터 | 스택 내에서 현재 작업의 위치를 가리키는 레지스터     |\n| 스레드 문맥 정보  | 문맥 교환 시 저장되고 복원되어야 할 정보         |\n\n\n\n\n\n\n\n"},{"excerpt":"문맥교환(Context Switching) 하나의 프로세스에서 다른 프로세스로 실행 순서가 넘어가면 어떤 일이 발생할까요? 프로세스 A가 CPU를 사용하다가 사용 시간이 끝나서 프로세스 B로 넘어간다면, A프로세스의 정보를\n저장하여야 합니다. 이곳에서는 이전에 보았던 PCB의 값인 레지스터 값, 메모리 정보등 중간 정보를 저장하여야\n이후 자신의 차례가 왔…","fields":{"slug":"/8/"},"frontmatter":{"date":"September 11, 2025","title":"문맥교환 그리고 프로세스 상태 변화, 프로세스 계층과 생성 방식을 알아보기","tags":["운영체제"]},"rawMarkdownBody":"\n## 문맥교환(Context Switching)\n\n---\n하나의 프로세스에서 다른 프로세스로 실행 순서가 넘어가면 어떤 일이 발생할까요?\n\n프로세스 A가 CPU를 사용하다가 사용 시간이 끝나서 프로세스 B로 넘어간다면, A프로세스의 정보를\n저장하여야 합니다. 이곳에서는 이전에 보았던 PCB의 값인 레지스터 값, 메모리 정보등 중간 정보를 저장하여야\n이후 자신의 차례가 왔을 때 이 과정을 이어받아 작업을 수행할 수 있습니다.\n\n여기서 하나의 프로세스를 실행하기 위해 필요한 정보들을 문맥(Context)라고 부르게 됩니다.\n이러한 문맥값들은 PCB속에 저장됩니다.환\n\n<br>\n\n![img.png](context_switching.png)\n[사진출처](https://yoongrammer.tistory.com/53)\n\n결국 프로세스 A에서 B로 프로세스가 넘어가는 순간에 프로세스 A정보를 백업하고 그작업이 끝난다면\n프로세스 B의 문맥을 불러오게 되며 이 것이 프로세스를 교대하는 방법입니다.\n\n문맥교환을 통해 여러개의 프로세스가 병렬적으로 시행되는 것 처럼 보이게 하지만 이러한 문맥교환은\n오버헤드가 발생할 수 있기 때문에 문맥교환이 자주일어나면 오버헤드를 신경써야 합니다.\n\n<br>\n<br>\n\n## 프로세스 상태\n\n---\n\n이전에 PCB에 기록되는 정보 중 프로세스 상태가 있다고 합니다. 여기서 말하는 프로세스 상태는 생성이 되었는지\n혹은 CPU를 사용하는지와 같은 정보를 통칭해서 프로세스 상태라고 부르게 됩니다.\n\n<br>\n\n프로세스 상태는 크게 다섯가지로 나뉠 수 있습니다.\n\n![img.png](process_state.png)\n[사진출처](https://thebook.io/080367/0021/)\n\n<br>\n\n### 1. 생성 상태\n\n프로세스를 생성 중인 상태를 생성 상태라고 부릅니다. 메모리에 적재되어 PCB를 할당받은 상태를 생성상태라고 부르게 됩니다.\n생성 상태가 끝난다고 곧바로 실행되는 것이 아닌 준비 상태가 되어 실행되기를 기다리게 됩니다.\n\n<br>\n\n### 2. 준비 상태\n\n준비 상태는 당장 CPU를 할당받아 실행될 수 있지만, 차례가 오지않아 기다리고 있는 상태입니다.\n이 상태에서 준비가 되면 실행 상태로 넘어 갑니다. 그리고 다른 상태에서 다시 준비 상태로도 전환이 가능합니다.\n\n준비 상태인 프로세스를 실행 상태로 전환하는 것을 디스패치 라고 부릅니다.\n\n<br>\n\n### 3. 실행 상태\n\n실행 상태는 CPU를 할당받아 실행 중인 상태를 지칭 합니다. 실행 상태인 프로세스는 할당된 시간 동안 CPU를 사용할 수 있습니다.\n이때 제한된 시간내 프로세스를 완료하지 못한경우 준비 상태로 전환이 되며, I/O입력처럼 대기해야 하는 상황이 생기면\n대기 상태로 넘어가게 됩니다.\n\n<br>\n\n### 4. 대기 상태\n\n실행 상태에서 I/O입력과 같이 프로세스가 대기해야 하는 상황이 온다면 대기 상태로 진입하게 됩니다.\n대기 상태가 끝난다고 해도 실행 상태가 되는것이 아닌 준비 상태로 넘어가게 됩니다.\n\n<br>\n\n### 5. 종료 상태\n\n프로세스가 종료된 상태입니다. 이 상태에 도달하면 운영체제는 PCB와 프로세스가 사용한 메모리를 정리합니다.\n\n<br>\n<br>\n\n## 프로세스 계층 구조\n\n---\n\n프로세스는 실행 도중 시스템 호출을 통해 다른 프로세스를 생성할 수 있습니다.\n\n이때 새 프로세스를 생성한 프로세스를 부모 프로세스라고 부르게 되며, 생성 된 프로세스를 자식 프로세스라고\n부르게 됩니다.\n부모의 프로세스와 자식의 프로세스는 각각 고유한 PID를 가지며 자식프로세스에서 부모프로세스 PID를 PPID로 가지고 있기도 합니다.\n\n<br>\n\n![img.png](process_layer.png)\n[사진 출처: 혼자 공부하는 운영체제 저자:강민철]\n\n<br>\n<br>\n\n## 프로세스 생성기법\n\n---\n\n그렇다면 부모 프로세스가 어떻게 자식 프로세스를 생성 할까요?\n\n그 방법은 fork, exec라는 명령어를 통해서 생성하게 됩니다.\n\n부모 프로세스는 fork를 통해 자신의 복사본을 자식 프로세스로 생성해내고, 그 복사본은 exec명령어를 통해\n자신의 메모리 공간을 다른 프로그램으로 교체합니다.\n\n<br>\n\n![img.png](fork.png)\n\n<br>\n\n좀더 자세히 설명하면 fork, exec 모두 시스템 호출로 분류 됩니다.\n부모 프로세스는 fork 시스템 호출을 통해 자신의 복사본을 자식으로써 생성합니다.\n\n여기서 자식은 부모의 복사본이기 때문에 부모 프로세스의 자원들, 예를들면 메모리의 내용, 열린 파일의 목록등을\n상속하게 됩니다. 그렇다고 해서 모든 정보가 같지는 않습니다.\n\n왜냐하면, PID나 메모리 저장구조는 고유한 정보이기 때문에 fork로 만들어진 자식은 PID, 메모리 저장위치\n처럼 고유한 정보에 대해서는 개별적인 값을 가지고 있습니다.\n\n<br>\n\n![img.png](exec.png)\n\n<br>\n\nfork만 사용한 프로세스는 완전한 자식 프로세스라고 명하기는 조금 어렵습니다.\nPID와 같은 고유한 값을 제외한다면 부모가 가진 리소스를 동일하게 사용하는 대체품이기 때문입니다.\n\n그렇기 때문에 자식 프로세스는 자신의 프로세스를 가지기 위해 exec 시스템 호출을 하게 됩니다.\n\nexec 호출을 진행하게 되면 자신의 메모리 공간을 새로운 프로그램으로 덮어쓰게 됩니다.\n\n코드 영역과 데이터 영역의 내용이 실행한 프로그램으로 바뀌게 되고, 나머지 영역은 초기화 됩니다.\n\n"},{"excerpt":"프로세스란 무엇일까? 우리는 흔히 보조 기억장치에 있는 프로그램 정보를 메모리로 적재하고, 적재된 정보를 CPU가 읽어 사용하는 이 과정을 프로그램이 실행되었다 라고 표현합니다. 여기서 실행된 프로그램을 프로세스라는 개별적인 용어로 부르고 프로그램을 실행하는 과정을 프로세스를 생성한다고 표현합니다.  백그라운드 프로세스라고 해서 사용자와 상호작용하지 않는…","fields":{"slug":"/7/"},"frontmatter":{"date":"September 10, 2025","title":"프로세스와 PCB 그리고 메모리 구조에 대해서 알아보기","tags":["운영체제"]},"rawMarkdownBody":"\n## 프로세스란 무엇일까?\n\n---\n\n우리는 흔히 보조 기억장치에 있는 프로그램 정보를 메모리로 적재하고, 적재된 정보를 CPU가 읽어 사용하는 이 과정을 프로그램이 실행되었다 라고 표현합니다.\n\n여기서 실행된 프로그램을 **프로세스**라는 개별적인 용어로 부르고 프로그램을 실행하는 과정을 프로세스를 생성한다고 표현합니다.\n\n<br>\n<br>\n\n![img.png](process_in_mac.png)\n\n<br>\n위 사진처럼 보이는 것보다 더 많은 프로세스가 작동하고 있는데, 여기서 사용자가 볼 수 있는 프로세스를 포그라운드 프로세스 라며 명하며,\n보이지 않는 프로세스를 백그라운드 프로세스라고 부르게 됩니다. \n\n백그라운드 프로세스라고 해서 사용자와 상호작용하지 않는 다는 뜻은 아닌데 백그라운드 프로세스 중에서 사용자와 상호작용 하지 않고 자신의 일만을 수행하기 위해 존재하는\n프로세스를 **데몬(daemon)** 프로세스라고 명합니다.\n\n<br>\n\n## 프로세스 제어 블록(PCB)\n\n---\n\nCPU자원이 한정되어 있는 반면에, 모든 프로세스는 실행을 위해 CPU를 사용하여야 합니다. \n그렇기 떄문에 프로세스들은 한정된 시간 만 CPU를 사용하며 자신의 차례를 기다립니다.\n\n운영체제는 빠르게 번갈아 수행되는 프로세스의 실행 순서를 관리하고, 프로세스에 CPU와 여러가지 자원을 배분합니다.\n이를 위해 운영체제는 프로세스 제어 블록(PCB)를 이용합니다.\n\n<br>\n\nPCB는 커널 영역에 생성되고, 수많은 프로세스를 PCB를 통해 태그처럼 사용해 특정 프로세스를 식별하며 해당 프로세스를 처리하는데 필요한 정보를 판단합니다.\n\n즉, 가게 주인이 물건을 태그를 통해 판단하고 가격을 알 수 있고, 생산지를 알 수 있는 것처럼 PCB는 운영체제가 수 많은 프로세스를 식별하고 그 프로세스의 정보를 판단하게 돕습니다.\n\n<br>\n<br>\n\n## PCB의 구조\n\n---\n\n<br>\n\n![img.png](PCB.png)\n\n[사진 출처](https://binaryterms.com/process-control-block-pcb.html)\n\n<br>\n\n위 그림처럼 PCB는 프로세스를 식별하기 위해 여러가지 정보를 담고 있습니다. 프로세스의 ID나, \n레지스터의 값 혹은 상태같이 많은 정보를 담고있으며 이를 알아보고자 합니다.\n\n<br>\n\n### 프로세스 ID\n\n![img.png](process_id.png)\n\n프로세스 ID(PID)는 프로세스를 식별하기 위해 존재하는 고유 ID입니다. 메모장을 두개 킨다고 할지라도 다른 프로세스ID가\n만들어지는 것처럼 중복된 활동이여도 하나의 프로세스는 고유한 ID를 가지게 됩니다.\n\n<br>\n\n### 레지스터 값\n\n프로세스는 자신의 실행 차례가 돌아오면 이전까지 사용했던 레지스터의 중간값들을 모두 복원합니다.\n여기에는 프로그램 카운터가 속하게 됩니다.\n\n<br>\n\n### 프로세스 상태\n\n현재 프로세스가 어떤 상태인 기록합니다. 입출력장치를 사용하기 위해 기다리는지 혹은 CPU를 사용하고 있는 상태인지 와 같은\n상태를 기록하며 자세한 상태는 다음장에서 설명합니다.\n\n<br>\n\n### CPU 스케줄링 정보\n\n프로세스가 언제, 어떤 순서로 CPU를 할당받을지에 대한 정보도 PCB에 기록됩니다.\n\n<br>\n\n### 메모리 관리 정보\n\n프로세스마다 메모리에 저장된 위치가 다릅니다. 그렇기 떄문에 PCB에는 해당 프로세스가 저장된 메모리 위치를 기록해야 합니다.\n\n<br>\n<br>\n\n## 프로세스의 메모리 영역\n\n---\n\n프로세스가 생성되면 커널 영역에 PCB가 생성됩니다. 그렇다면 커널 영역이 아닌 사용자 영역에는 어떤 데이터가 들어갈까요?\n\n\n![img.png](memory_model.png)\n\n[사진출처](https://www.programmersought.com/article/98613694619/)\n\n위 그림처럼 하나의 프로세스는 크게 코드영역(Text), 데이터 영역(Bss,Gvar), 힙 영역(Heap), 스택 영역(Stack) 4가지로 나뉩니다.\n\n차례대로 설명하자면,\n\n<br>\n<br>\n\n### 코드영역 or 텍스트영역(Text)\n\n이곳에는 실행할 수 있는 기계어로 이루어진 명령어가 저장됩니다. 가공할 수 있는 데이터가 아닌\nCPU가 실행해야 하는 명령어가 담겨있기 때문에 읽기모드만 지원합니다.\n\n<br>\n\n### 데이터 영역\n\n프로그램을 실행하는 동안 유지되어야 하는 데이터가 저장되는 공간입니다. 대표적은 전역 변수가 이곳에 해당합니다.\n\n<br>\n\n### 코드영역 & 데이터 영역 공통점\n\n위 두 영역은 크기가 변하지 않습니다. 프로그램을 구성하는 명령어가 작동중에 코드 양이 늘어나는 경우가 없으니\n이 두가지 영역을 정적 할당 영역이라고 부릅니다.\n\n<br>\n\n### 힙 영역\n\n프로그래머가 직접 할당할 수 있는 공간입니다. 프로그래밍 과정에서 힙 영역에 데이터를 할당했다면 언젠가는 이 영역에 \n데이터를 반환해야 합니다. 그렇지 않다면 메모리 용량은 점점 줄어들어 장애가 발생할 수 있습니다.\n\n이런 문제를 메모리를 할당받고 해제 하지 않았다고 하여 누수가 발생했다. 즉 메모리 누수라고 부릅니다.\n\n<br>\n\n### 스택 영역\n\n스택 영역은 데이터를 일시적으로 저장하는 공간입니다.\n데이터 영역에 담기는 값과는 다르게 잠깐 쓸 데이터를 담아두는 공간입니다.\n함수를 실행하는 동안 필요한 지역변수, 매개 변수가 이곳에 해당합니다.\n그렇기 떄문에 함수가 종료되면 스택 영역에서 해당 함수에 쓰였던 변수들도 같이 없어지게 됩니다.\n\n<br>\n<br>\n\n### 힙 영역 & 스택 영역 공통점\n\n위 두 영역은 실시간으로 그 크기가 변할 수 있고 그렇기 떄문에 동적 할당 영역이라고 부르게 됩니다.\n\n그림을 보면 unused memory영역이 있는데, 스택 영역과 힙 영역이 동적이기 떄문에 힙은 아래에서 위로, 스택은 \n위에서 아래로 주소를 할당하게 됩니다. 그렇게 되면 서로 충돌없이 동적으로 값을 할당할 수 있기 때문입니다.\n\n여기서 만약에 힙이나 스택에 많은 정보가 담겨서 서로의 지점을 충돌 할 수 있는데, 그럴때 각각 stack overflow,\nheap overflow라고 부르게 됩니다.\n\n\n\n\n\n"},{"excerpt":"IO란 개발을 하다 보면 I/O라는 용어를 자주 듣게 됩니다. I/O는 Input/Output의 줄임말로, 컴퓨터가 외부와 데이터를\n주고받는 일련의 작업을 통칭 I/O라고 부르게 됩니다. 예시를 들어서 파일 읽기/쓰기 (문서를 열거나 저장하는 행위) 네트워크 통신(웹사이트 접속, 이메일 전송) 데이터베이스 조회(회원 정보 검색) 이런 일련의 행위는 공통적…","fields":{"slug":"/6/"},"frontmatter":{"date":"September 09, 2025","title":"동기식/비동기식 I/O의 차이와 활용 사례","tags":["운영체제"]},"rawMarkdownBody":"\n## IO란\n\n개발을 하다 보면 I/O라는 용어를 자주 듣게 됩니다. I/O는 Input/Output의 줄임말로, 컴퓨터가 외부와 데이터를\n주고받는 일련의 작업을 통칭 I/O라고 부르게 됩니다.\n\n예시를 들어서\n\n- 파일 읽기/쓰기 (문서를 열거나 저장하는 행위)\n- 네트워크 통신(웹사이트 접속, 이메일 전송)\n- 데이터베이스 조회(회원 정보 검색)\n\n이런 일련의 행위는 공통적인 특징이 있는데, 물리적인 시간이 걸린다는 점입니다.\n그렇기 떄문에 IO를 어떻게 다룰까에 대한 방법또한 여러가지 존재합니다.\n\n<br>\n<br>\n\n## 동기와 비동기란\n\nIO를 다루는 방법에는 동기, 비동기에 대한 개념이 등장합니다.\n이러한 개념을 사전에 정의 하고 내려가겠습니다.\n\n### 동기 (Synchronous)\n\n프로그램에서 말하는 동기란 하나의 작업에 대해서 요청과 응답 과정을 기다리는 행위입니다.\n예를들어, WAS가 데이터베이스에 조회 요청을 하고 데이터베이스는 요청받은 데이터를 돌려줄것입니다.\n이 과정에서 WAS는 요청직후 부터 응답을 받을때 까지 과정에서 데이터베이스의 응답을 기다리게 됩니다. 이것이 동기입니다.\n\n<br>\n\n### 동기의 특징\n\n순차적 실행: 한 작업이 완료되어야 다음 작업이 시작\n블로킹: 현재 작업이 끝날 때까지 다른 작업은 대기\n예측 가능: 코드가 위에서 아래로 순서대로 실행\n\n<br>\n<br>\n\n### 비동기 (Asynchronous)\n\n그렇다면 비동기는 하나의 작업에 대해서 요청과 응답 과정을 기다리지 않는 행위입니다.\n예를들어, WAS가 데이터베이스에 조회 요청을 하게 되면 데이터베이스가 이를 수행하고 응답할것입니다.\n이 과정 사이에 시간동안 WAS는 본인의 다른 작업을 수행하다가 데이터베이스의 응답을 받게 됩니다.\n즉 요청과 응답 사이 기간동안 WAS는 본인의 일을 하며 무작정 기다리지 않는 것입니다.\n\n<br>\n\n### 비동기의 특징\n\n동시 실행: 여러 작업을 동시에 시작 가능\n논블로킹: 작업 완료를 기다리지 않고 다른 작업 진행\n콜백/Promise: 작업 완료 시 결과를 알려주는 방식\n\n<br>\n\n## 동기식 I/O\n\n![img.png](synchronous_io.png)\n\n<br>\n\n동기식IO는 IO요청이 발생하였을 때 이전 동기 설명처럼 IO요청이 끝날때 까지 기다리는 방식입니다.\n프로그램이 IO작업을 요청하게 되면, 다른 동작을 수행하지 않고 멈춰서 IO작업이 리턴되기 까지 기다립니다.\nI/O작업이 완료되면 인터럽트를 통해 완료를 알리게 됩니다. 이후 CPU 제어권이 기존 프로그램에게 넘어가게 됩니다.\n\n이러한 방식의 특징은 구현이 쉽다는 특징이 있지만, 연산에 대한 기다림으로 인해 자원 낭비를 하는 특징이 있습니다.\n\n## 비동기식 I/O\n\n![img.png](asynchronous_io.png)\n\n비동기식IO는 IO요청이 발생하였을 떄 이전 비동기 설명처럼 IO요청을 기다리지 않는 방식입니다.\n프로그램이 IO 작업을 요청하고, 그 작업이 완료되기를 기다리지 않고 즉시 다음 작업으로 넘어가는 방식입니다.\n\n이러한 방식의 특징은 구현의 복잡성이 높다는 것이지만, 대용량 데이터를 처리하는데 여러 IO작업을 동시에 처리해야 할 떄 유용합니다.\n"},{"excerpt":"쓰레드란? 쓰레드는 프로세스를 구성하는 실행 흐름의 단위를 의미합니다.  그래서 하나의 프로세스는 1개 이상의 쓰레드를 가집니다.\n이로 인해 하나의 프로세스에서 여러 작업을 동시에 수행할 수 있습니다. 사용자 수준 쓰레드와 커널 수준 쓰레드의 차이 사용자 수준 쓰레드란, 라이브러리를 통해 구현한 쓰레드를 의미합니다.\n쓰레드와 관련된 모든 행위를 사용자 영…","fields":{"slug":"/4/"},"frontmatter":{"date":"September 08, 2025","title":"4. 쓰레드 ","tags":["운영체제"]},"rawMarkdownBody":"\n## 쓰레드란?\n\n쓰레드는 프로세스를 구성하는 실행 흐름의 단위를 의미합니다. \n\n![](img.png)\n\n그래서 하나의 프로세스는 1개 이상의 쓰레드를 가집니다.\n이로 인해 하나의 프로세스에서 여러 작업을 동시에 수행할 수 있습니다.\n\n> #### 사용자 수준 쓰레드와 커널 수준 쓰레드의 차이 \n> 사용자 수준 쓰레드란, 라이브러리를 통해 구현한 쓰레드를 의미합니다. \n> 쓰레드와 관련된 모든 행위를 사용자 영역에서 하기 때문에, \n> 커널은 사용자 수준 쓰레드의 존재를 알지 못하고 쓰레드 교환에 개입하지 않습니다. \n> 커널 수준 쓰레드란, 커널이 직접 생성하고 관리하는 쓰레드를 의미합니다.\n\n## 쓰레드의 메모리 공간\n\n같은 프로세스의 쓰레드는 프로세스로부터 각각의 스택을 나눠갖지만 Code, Data, Heap 메모리 영역을 공유합니다.\n하지만, 쓰레드 ID, 스택, PC나 레지스터 같은 쓰레드 컨텍스트에 대해서는 각기 다른 값을 가지고 있습니다.\n\n![](img_1.png)\n\n이렇게 각자의 PC, 레지스터, 스택을 가지고 있기에 쓰레드마다 독립적으로 실행할 수 있습니다.\n\n여기서 중요한 점은 프로세스의 쓰레드들은 실행에 필요한 최소한의 정보(PC, 레지스터, 스택)만을 유지한 채\n프로세스 자원을 공유하며 실행된다는 점입니다.\n\n## TCB(쓰레드 제어블록)\n\n쓰레드 또한 프로세스의 PCB(프로세스 제어 블록)처럼 TCB(쓰레드 제어 블록)을 통해 관리됩니다.\nTCB는 각 쓰레드에 위치하고, 커널은 TCB를 통해 쓰레드를 관리합니다.\n\n그럼 TCB에는 어떤 정보가 담겨있을까요?\nTCB에는 아래와 같은 쓰레드의 메타데이터들이 담겨져 있습니다.\n\n![](img_2.png)\n\n- 쓰레드 번호(TID, Thread ID): 각 쓰레드의 고유 식별 번호입니다.\n- 스택 포인터 (Stack Pointer): 쓰레드가 존재하는 프로세스의 PCB에 대한 포인터\n- 프로그램 카운터(PC, Program Counter): 이 쓰레드에서 실행될 다음 명령어의 주소를 가리키는 포인터(주소)입니다.\n- 쓰레드 상태(Thread State): 쓰레드가 현재 어떤 상태인지를 나타내는 정보(new, ready, running, waiting, end)입니다.\n- 레지스터 상태(Register State): 쓰레드의 레지스터 값 세트입니다.\n\n각 프로세스에 대한 중요 정보를 강조하는 특정 정보가 쓰레드 제어 블록에 저장됩니다.\n\n## 프로세스와 쓰레드의 차이\n\n프로세스는 각각 독립된 메모리 영역(Code, Data, Heap, Stack)을 할당받고 고유 프로세스 ID를 가지는 특성으로 인해,\n프로세스끼리는 서로의 영역에 접근할 수 없습니다.\n그래서 한 프로세스가 다른 프로세스의 자원에 접근하려면 IPC(inter-process communication)을 사용해야 합니다.\n\n하지만, 쓰레드는 IPC와 같은 별도의 통신 방법 없이도 앞서 언급한 것처럼 프로세스의 Code, Data, Heap 메모리 영역을 공유합니다.\n\n이처럼 프로세스들 사이의 통신에 대한 어려움 해소 및 빠른 컨텍스트 스위칭으로 인해 쓰레드가 프로세스보다 더 가벼운 실행 단위로 사용됩니다.\n이로 인해 현대에 와서 운영체제의 실행단위는 프로세스에서 쓰레드로 바뀌어 가고 있습니다.\n\n## 동시성 환경에서의 차이\n\n동시성 환경에서는 어떤지 알아볼까요?\n여러 프로세스를 동시에 실행하는 멀티 프로세스와 한 프로세스에서 여러 쓰레드를 동시에 실행하는 멀티 쓰레드가 있습니다.\n\n\n![](img_3.png)\n\n여기서 가장 큰 차이점은 프로세스끼리는 기본적으로 공유하지 않지만, 쓰레드끼리는 같은 프로세스 내의 자원을 공유한다는 점입니다.\n\n즉, 멀티 프로세스는 여러 프로세스를 동시에 실행해 각각의 독립적인 프로세스 간 자원을 공유하지 않기 때문에 프로세스 간 통신 (IPC) 방식을 써야 합니다.\n또한, 메모리에 동일한 내용들이 중복해서 존재하기 때문에 메모리에도 부담이 될 수 있습니다.\n그러나 한편으로는 자원을 공유하지 않는 덕분에 하나의 프로세스에 문제가 생겨도 다른 프로세스들에는 문제가 발생하지 않는다는 장점이 있기도 합니다.\n\n반면, 멀티 쓰레드는 실행에 필요한 최소한의 정보(PC, 레지스터, 스택)만을 유지한 채 프로세스 자원을 공유하며 실행되기에\n커널의 개입 없이 쓰레드간 통신을 할 수 있고, 메모리에도 부담이 덜합니다.\n또한 fork로 인한 생성이 공유하는 부분을 제외한 부분만 복사하면 되기 때문에 프로세스보다 빠릅니다.(쓰레드가 접근하는 공유 데이터에 대해 동기화 작업을 수행해야 합니다)\n<br>\n하지만, 하나의 쓰레드에 문제가 생기면 같은 프로세스 내의 다른 쓰레드들에도 문제가 발생할 수 있다는 단점이 있습니다.\n"},{"excerpt":"프로세스란?  컴퓨팅에서 프로세스란 운영체제로부터 메모리 공간을 할당받아 실행 중인 프로그램의 인스턴스를 의미합니다.\n여기서 논하는 프로그램이란, 일반적으로 하드 디스크와 같은 저장장치에 저장되어 있는 실행 코드를 뜻합니다. 프로세스의 메모리 공간 프로세스는 다음 4개의 메모리 영역으로 구성되고 가상 메모리 공간에 독립적으로 형성됩니다. 코드 영역(Cod…","fields":{"slug":"/3/"},"frontmatter":{"date":"September 08, 2025","title":"3. 프로세스","tags":["운영체제"]},"rawMarkdownBody":"\n## 프로세스란? \n\n![](img.png)\n\n컴퓨팅에서 프로세스란 운영체제로부터 메모리 공간을 할당받아 실행 중인 프로그램의 [인스턴스](https://ko.wikipedia.org/wiki/%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4_(%EC%BB%B4%ED%93%A8%ED%84%B0_%EA%B3%BC%ED%95%99)#:~:text=%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4(instance)%EB%8A%94%20%ED%95%B4%EB%8B%B9%20%ED%81%B4%EB%9E%98%EC%8A%A4%EC%9D%98%20%EA%B5%AC%EC%A1%B0%EB%A1%9C%20%EC%BB%B4%ED%93%A8%ED%84%B0%20%EC%A0%80%EC%9E%A5%EA%B3%B5%EA%B0%84%EC%97%90%EC%84%9C%20%ED%95%A0%EB%8B%B9%EB%90%9C%20%EC%8B%A4%EC%B2%B4%EB%A5%BC%20%EC%9D%98%EB%AF%B8%ED%95%9C%EB%8B%A4.)를 의미합니다.\n여기서 논하는 프로그램이란, 일반적으로 하드 디스크와 같은 저장장치에 저장되어 있는 실행 코드를 뜻합니다.\n\n## 프로세스의 메모리 공간\n\n프로세스는 다음 4개의 메모리 영역으로 구성되고 [가상 메모리](https://ko.wikipedia.org/wiki/%EA%B0%80%EC%83%81_%EB%A9%94%EB%AA%A8%EB%A6%AC#:~:text=%EA%B0%80%EC%83%81%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EB%98%90%EB%8A%94%20%EA%B0%80%EC%83%81%20%EA%B8%B0%EC%96%B5%20%EC%9E%A5%EC%B9%98(%EB%AC%B8%ED%99%94%EC%96%B4%3A%20%EA%B0%80%EC%83%81%EA%B8%B0%EC%96%B5%EA%B8%B0%2C%20virtual%20memory%2C%20virtual%20storage)%EB%8A%94%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EA%B4%80%EB%A6%AC%20%EA%B8%B0%EB%B2%95%EC%9D%98%20%ED%95%98%EB%82%98%EB%A1%9C%2C%20%EC%BB%B4%ED%93%A8%ED%84%B0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%20%EC%8B%A4%EC%A0%9C%EB%A1%9C%20%EC%9D%B4%EC%9A%A9%20%EA%B0%80%EB%8A%A5%ED%95%9C%20%EA%B8%B0%EC%96%B5%20%EC%9E%90%EC%9B%90%EC%9D%84%20%EC%9D%B4%EC%83%81%EC%A0%81%EC%9C%BC%EB%A1%9C%20%EC%B6%94%EC%83%81%ED%99%94%ED%95%98%EC%97%AC%5B1%5D%20%EC%82%AC%EC%9A%A9%EC%9E%90%EB%93%A4%EC%97%90%EA%B2%8C%20%EB%A7%A4%EC%9A%B0%20%ED%81%B0%20(%EC%A3%BC)%20%EB%A9%94%EB%AA%A8%EB%A6%AC%EB%A1%9C%20%EB%B3%B4%EC%9D%B4%EA%B2%8C%20%EB%A7%8C%EB%93%9C%EB%8A%94%20%EA%B2%83%EC%9D%84%20%EB%A7%90%ED%95%9C%EB%8B%A4.%5B2%5D%20%EA%B0%81%20%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8%EC%97%90%20%EC%8B%A4%EC%A0%9C%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EC%A3%BC%EC%86%8C%EA%B0%80%20%EC%95%84%EB%8B%8C%20%EA%B0%80%EC%83%81%EC%9D%98%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EC%A3%BC%EC%86%8C%EB%A5%BC%20%EC%A3%BC%EB%8A%94%20%EB%B0%A9%EC%8B%9D%EC%9D%B4%EB%8B%A4.) 공간에 독립적으로 형성됩니다.\n\n- 코드 영역(Code) : 프로그램 실행 코드가 적재되는 영역입니다. 읽기 모드만 지원합니다.\n- 데이터 영역(Data) : 프로세스의 초기화 된 데이터들인 전역 변수와 정적 변수들이 적재되는 영역입니다.\n- 힙 영역(Heap) : 런타임 동안 생성된 데이터를 보관하기 위해 동적으로 할당받는 영역입니다.\n- 스택 영역(Stack) : 지역변수, 매개변수, 리턴 값, 복귀 주소 등이 저장되는 영역입니다.\n\n이렇게 영역이 나눠진 이유는 최대한 중복적인 데이터를 방지하여 메모리 사용량을 줄이는데 목적이 있습니다.\n\n> 예를 들면, 코드에서 공통으로 사용하는 부분을 전역 변수로 지정하는 행위와 같다.\n\n## PCB(프로세스 제어 블록)\n\n커널은 시스템 전체에 대해 레지스터에 하나의 프로세스 테이블을 두고 모든 프로세스의 정보를 관리합니다.\n여기서의 프로세스 정보는 해당 프로세스를 실행하기 위해 필요한 정보들로 컨텍스트라고 부릅니다. \n여기서 프로세스의 상태에 따라 프로세스를 교체하는 작업인 컨텍스트 스위칭 작업 이루어 지는데,\n이와 같은 상황에서 여러 프로세스를 관리하기 위해 각 프로세스들에 대해 식별이 가능해야 관리가 가능하기에 해당 프로세스의 정보가 필요합니다.\n\n예를 들어, 인터럽트가 발생해서 자원을 할당받은 프로세스가 대기 상태가 되고 다른 프로세스를 실행 상태로 올릴 때\n대기 중인 프로세스를 나중에 다시 수행하기 위해 대기 중인 프로세스의 상태와 같은 정보를 알아야 할 것입니다.\n\n운영체제의 커널은 이러한 이유로 활성된 프로세스를 관리하기 위해 해당 프로세스에 대한 정보를 PCB(프로세스 제어 블록)이라는 데이터 구조에 저장합니다.\n(\"PCB는 운영 체제가 프로세스를 표현한 것이다.\"라는 말도 있습니다.)\n\n![](img_1.png)\n\n> PCB는 해당 프로세스가 실행되면 생성되어 종료 시 제거가 되는데 이 과정에서 PCB의 삽입 및 삭제가 용이한 연결 리스트(Linked List) 방식으로 관리됩니다.\n\n## Process Metadata\n\n그럼 PCB에는 어떤 정보가 담겨있을까요?\nPCB에는 아래와 같은 프로세스의 메타데이터들이 담겨져 있습니다.\n\n- 프로세스 번호(PID, Process ID): 각 프로세스의 고유 식별 번호입니다.(PPID: 부모 프로세스 ID)\n- 프로세스 상태(Process State): 프로세스가 현재 어떤 상태인지를 나타내는 정보(new, ready, running, waiting, end)입니다.\n- 프로그램 카운터(PC, Program Counter): 이 프로세스에서 실행될 다음 명령어의 주소를 가리키는 포인터(주소)입니다.\n- 레지스터 상태(Register State): 프로세스의 레지스터 값 세트로, 프로세스를 다시 실행할 때 현재 상태를 복원하는 데 사용됩니다. \n- 스케줄링 정보(Scheduling Information): CPU 시간 스케줄링에 대한 정보입니다.\n- 메모리 관리 정보 (Memory Management Information): 프로세스의 메모리 할당과 사용에 관한 정보입니다.\n- 입출력 상태 (I/O Status): 프로세스가 입출력 작업을 수행 중인 경우, 해당 상태 정보 및 장치 정보입니다.\n\n## 프로세스 상태\n\n운영체제의 커널은 프로세스를 관리하기 위해 프로세스 정보를 알아야 해서 PCB를 생성하는 것을 알았습니다.\n여기서 커널의 프로세스 관리는 프로세스 상태를 관리하는 것이기도 합니다.\n\n프로세스 상태는 위에서 언급한대로 프로세스가 현재 어떤 상태인지를 나타내는 정보로, \n프로세스의 상태에 따라 CPU를 할당하거나 대기 상태로 전환하는 등의 작업이 이루어집니다.\n프로세스 상태는 일반적으로 다음과 같은 상태로 구분됩니다.\n\n![](img_2.png)\n\n- New(생성) : 프로세스는 저장장치에서 메모리로 로드되어 생성됩니다. 이후 커널은 메모리를 할당하고 PCB를 생성하고 프로세스 테이블에 등록합니다. 실행 준비를 마치면 ready 상태로 전이됩니다.\n- Ready(준비) : 프로세스가 CPU를 사용하고 있지는 않지만 언제든지 사용할 수 있는 상태로, 해당 상태의 프로세스들은 커널에 있는 준비 큐([우선순위 큐](https://ko.wikipedia.org/wiki/%EB%B9%84%EC%9C%A8_%EB%8B%A8%EC%A1%B0_%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81))에 들어갑니다. 스케줄러가 컨텍스트 스위칭을 수행할 때, 준비 큐에서 우선순위가 높은 프로세스가 CPU 스케줄링에 따라 리소스를 할당받아 running 상태로 전이(디스패치)됩니다.\n- Running(실행) : 프로세스가 CPU를 차지하여 명령어들이 실행되고 있는 상태입니다. 할당된 시간을 모두 사용(타임아웃)했다면 타이머 인터럽트가 발생되어 준비 상태로 전이되고, 입출력 요청이나 자원 요청 등으로 인해 대기 상태로 전이될 수도 있습니다.\n- Waiting(대기) : 프로세스 실행 도중 입출력 완료(주된 원인)와 같은 수신 등을 대기하는 상태를 말합니다.\n- End(=terminated, 종료) : 프로세스의 실행이 종료된 상태입니다. 이떄, PCB와 프로세스의 메모리를 해제 또는 정리합니다.\n\n## 프로세스 계층 구조\n\n프로세스는 실행 도중 시스템 콜을 통해 다른 프로세스를 생성할 수 있습니다. \n이때 시스템 콜을 호출한 프로세스를 부모 프로세스, 생성된 프로세스를 자식 프로세스라 합니다.\n\n> 서로 다른 프로세스라 서로 다른 PID를 가집니다. \n> 일부 운영체제에서는 자식 프로세스의 PCB에 부모 프로세스의 PID (PPID)가 기록되기도 합니다.\n\n프로세스 생성 기법은 복제와 교체 과정을 통한 방식을 사용합니다.\n\n![](img_3.png)\n\n흐름의 시작인 부모 프로세스는 fork(복제) 시스템 콜을 통해 자신의 복사본을 자식 프로세스로 생성합니다.\n자식 프로세스는 exec(교체) 시스템 콜을 통해 자신의 메모리 공간을 다른 프로그램으로 교체합니다.\n이때, 자식 프로세스의 메모리 공간을 새로운 프로그램으로 덮어쓰게 합니다.(코드/데이터는 내용만 바꾸고, 나머지는 초기화)\n자식 프로세스가 exec 시스템 콜을 호출하지 않을 경우, 부모 프로세스와 자식 프로세스는 같은 코드를 병행하여 실행하는 프로세스가 됩니다.\n이러한 과정을 통해 프로세스는 계층 구조를 이루어 관리할 수 있습니다.\n\n많은 운영체제에서는 이처럼 프로세스를 낳는 계층적인 구조로써 프로세스들을 관리합니다.\n컴퓨터가 부팅될 때 실행되는 최초의 프로세스가 자식 프로세스들을 생성하고, \n생성된 자식 프로세스들이 새로운 프로세스들을 낳는 형식으로 여러 프로세스가 동시에 실행되는 것입니다.\n\n## 프로세스 간 통신\n\n앞서 언급했던 것처럼 프로세스는 서로 독립된 메모리 공간을 가지므로, 프로세스끼리는 서로의 영역에 접근 또는 간섭할 수 없습니다.\n이러한 이유로 통신이 필요할 경우, [IPC](https://ko.wikipedia.org/wiki/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EA%B0%84_%ED%86%B5%EC%8B%A0#:~:text=%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%20%EA%B0%84%20%ED%86%B5%EC%8B%A0(Inter%2DProcess%20Communication%2C%20IPC)%EC%9D%B4%EB%9E%80%20%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EB%93%A4%20%EC%82%AC%EC%9D%B4%EC%97%90%20%EC%84%9C%EB%A1%9C%20%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC%20%EC%A3%BC%EA%B3%A0%EB%B0%9B%EB%8A%94%20%ED%96%89%EC%9C%84%20%EB%98%90%EB%8A%94%20%EA%B7%B8%EC%97%90%20%EB%8C%80%ED%95%9C%20%EB%B0%A9%EB%B2%95%EC%9D%B4%EB%82%98%20%EA%B2%BD%EB%A1%9C%EB%A5%BC%20%EB%9C%BB%ED%95%9C%EB%8B%A4.)를 통해 프로세스 간에 통신을 할 수 있습니다.\nIPC에는 공유 메모리를 이용한 통신과 파일을 통한 프로세스 간 통신 이렇게 두 가지 방법이 있습니다.\n\n>  IPC 통신 시, 프로세스 간 데이터를 동기화하고 보호하기 위해 [세마포어](https://ko.wikipedia.org/wiki/%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4)와 [뮤텍스](https://ko.wikipedia.org/wiki/%EC%83%81%ED%98%B8_%EB%B0%B0%EC%A0%9C)를 사용합니다."},{"excerpt":"인터럽트 기반 입출력 인터럽트는 컴퓨터 시스템에서 현재 실행 중인 프로세스를 중단 하고, 인터럽트를 발생시킨 작업을 처리하기 위한\n방법 혹은 과정 이다. 인터럽트는 CPU의 실행 흐름을 중단시키고 인터럽트가 끝난 후 원래의 흐름으로 돌아가는 방식을 가진다. 인터럽트는 크게 두가지로 나뉘게 되며, 소프트웨어 혹은 하드웨어 인터럽트로 나누어지며 이는 인터럽트…","fields":{"slug":"/5/"},"frontmatter":{"date":"September 08, 2025","title":"인터럽트와 DMA를 통한 효율적 입출력 처리","tags":["운영체제"]},"rawMarkdownBody":"\n## 인터럽트 기반 입출력\n\n---\n\n인터럽트는 컴퓨터 시스템에서 현재 실행 중인 프로세스를 중단 하고, 인터럽트를 발생시킨 작업을 처리하기 위한\n방법 혹은 과정 이다. 인터럽트는 CPU의 실행 흐름을 중단시키고 인터럽트가 끝난 후 원래의 흐름으로 돌아가는 방식을 가진다.\n\n인터럽트는 크게 두가지로 나뉘게 되며, 소프트웨어 혹은 하드웨어 인터럽트로 나누어지며 이는 인터럽트를 발생시킨\n주체가 무엇인가에 따라 나뉘게 된다.\n\n대표적인 하드웨어 인터럽트는 I/O완료, 대표적인 소프트웨어 인터럽트는 시스템 콜이 있다.\n\n<br>\n<br>\n\n![img.png](Interrupts.png)\n\n이러한 인터럽트 기반 입출력의 순서를 설명하자면\n\n1. CPU가 입출력 장치에 대해 입출력 요청을 보낸다.\n2. CPU는 요청이후 다른 작업을 수행한다.\n3. 입출력 장치가 준비되면 인터럽트를 발생시킨다.\n4. CPU는 현재 실행 중인 작업을 중단하고 인터럽트 서비스 루틴(ISR)을 실행한다.\n5. 데이터를 처리한 후 , CPU는 원래 수행하던 작업을 계속 실행한다.\n\n이러한 인터럽트 기반 입출력의 단점은 인터럽트가 많이 발생하는 상황에서 CPU가 부하될 수 있다는 단점이 있다.\n\n\n<br>\n<br>\n\n## DMA(Direct Memory Access 직접 메모리 접근)\n\n---\n\nDMA방식은 이름에서 볼 수 있듯이 CPU를 사용하지 않고 입출력 장치가 직접 메로리와 데이터를 교환합니다.\n\n이것이 가능한 이유는 DMA 컨트롤러가 존재해, 메모리와 입출력 장치 사이의 데이터를 관리하기 때문입니다.\n\nDMA에서는 CPU가 전송할 데이터의 위치, 포인터, 바이트 크기만 DMA 컨트롤러에 전달하면, \nDMA가 입출력 작업을 대신 처리하고 전체 작업이 완료될 때만 CPU에 인터럽트를 보냅니다. \n이로 인해 CPU와 여러 입출력 장치가 직접 연결되던 기존 구조에서 CPU-DMA-입출력 장치 구조로 변화했고,\nCPU의 가용 시간이 현저히 증가하는 효과를 얻었습니다. \n이는 교수가 조교에게 학생 관리를 맡기고 최종 결과만 확인하는 것에 비유할 수 있으며, \n현재 DMA는 많은 컴퓨터 장치에서 보편적으로 사용되는 기술이 되었습니다.\n\n<br>\n<br>\n\n![img.png](DMA.png)\n\n<br>\nDMA 방식을 순서로 설명하자면\n\n1. CPU가 DMA 컨트롤러에게 입출력 요청합니다.\n2. DMA 컨트롤러가 메모리와 입출력 장치 간의 데이터 전송을 직접 수행합니다.\n3. 데이터 전송이 완료되면 DMA 컨트롤러가 인터럽트를 발생 시켜 CPU에게 완료를 알립니다.\n4. CPU는 인터럽트를 받아서 필요한 후처리 수행합니다.\n\n\n"},{"excerpt":"단일 프로세스 초창기 컴퓨터를 상상하면 지금처럼 복잡한 방법이 아닌, 한번에 하나의 프로그램만 실행 할 수 있었을것이다.\n이 말은 다른 프로그램을 사용 해야 하는 순간 기존 프로그램이 종료 되거나,\n끝날때 까지 기다려야 합니다.  멀티 프로그래밍  이러한 문제를 해결하기 위해 어쩔 수 없이 작업이 멈추는 구간에 다른 작업을 진행하는 방법을 사용하게 된다.…","fields":{"slug":"/4/"},"frontmatter":{"date":"September 07, 2025","title":"멀티프로그래밍, 시분할 시스템, 멀티프로세싱 개념","tags":["운영체제"]},"rawMarkdownBody":"\n## 단일 프로세스\n\n---\n\n초창기 컴퓨터를 상상하면 지금처럼 복잡한 방법이 아닌, 한번에 하나의 프로그램만 실행 할 수 있었을것이다.\n이 말은 다른 프로그램을 사용 해야 하는 순간 기존 프로그램이 종료 되거나,\n끝날때 까지 기다려야 합니다.\n\n<br>\n\n![img.png](single_process.png)\n\n<br>\nCPU 관점에서 본다면 특정 작업을 수행중 IO 작업이 생긴다면 IO작업동안 CPU는 멈추게\n될것이고 그 상황에서 CPU가 놀고 있게 되는 시간이 늘어나는 것입니다.\n\n<br>\n\n## 멀티 프로그래밍\n\n![img.png](multiprograming.png)\n\n이러한 문제를 해결하기 위해 어쩔 수 없이 작업이 멈추는 구간에 다른 작업을 진행하는 방법을 사용하게 된다.\n이를 멀티 프로그래밍이라고 부르며 그림처럼 CPU 사용률을 높이기 위한 목적이었습니다.\n\n하지만 이러한 방식의 문제는 앞선 프로세스가 길어질 수록 즉 IO사용처럼 비는 시간없이 순수하게 많은 시간을\n쓰게 된다면 이후 프로세스가 계속 기다려야 하는 문제가 있었습니다.\n\n<br>\n\n## 멀티 태스킹\n\n![img.png](multitasking.png)\n\n멀티 프로그래밍 방식에서 더 나아가 모든 프로세스가 공정하게 특정 짧은 시간만 실행되게 반복한다면 길게 시행되는\n프로세스 뒤에 오는 프로세스가 기다리는 문제가 없을 것이다. 이것이 멀티태스킹을 사용하는 이유입니다.\n\n**프로세스1**에서 **프로세스2**로 작업을 스위칭 하는것을 문맥 교환(Context Switching)이라고\n부르게 되는데 이러한 문맥교환은 값싼 작업이 아니고 이러한 작업이 자주 일어나게 된다면 비효율 적인 단점이 부각되다 보니\n새로운 방식을 사용하게 됩니다.\n\n<br>\n\n## 멀티 프로세싱\n\n멀티 프로세싱이란 이전 멀티 태스킹과 이름은 비슷 하지만 완전히 다른 방식입니다.\n\n이전 방식은 하나의 **CPU**를 어떻게 쪼개서 사용할까라는 목적이였다면, **멀티 프로세싱**은 **CPU** 작업단위인\n코어 자체를 늘려서 여러 CPU코어가 동시에 작업하는것을 멀티 프로세싱이라고 부르게 됩니다.\n\n![img.png](multiprocessing.png)\n\n멀티 프로세싱은 CPU코어 수를 늘리는 방법이기 때문에, 이를 어떻게 처리할까에 대한 내용은 멀티 프로세싱 자체의 내용이 아니고 앞서 나왔던 방법론을 도입할 수 있습니다.\n그림처럼 하나의 프로세스를 여러 코어가 담당하는 방법이나, 여러 프로세스를 여러 코어가 담당 할 수 도 있습니다.\n\n### 출처\n[사진출처](https://medium.com/@ashappyasiknow/single-process-system-multi-programming-multitasking-%EC%9D%B4%EB%9E%80-9f9b65ec0311)\n"},{"excerpt":"이중모드 운영체제는 자원을 충돌 없이 효율적으로 사용하기 위해 자원 관리의 진입점이 된다고 말했습니다. 그럼 일반 응용프로그램은 어떻게 자원에 접근 할 수 있을까요? 이에 대한 답은 이중 모드 입니다.  위 사진 처럼 CPU가 명령을 실행하는 방식을 사용자 모드 와 커널 모드로 나누어 사용하게 됩니다. 사용자 모드 사용자 모드는 운영체제 서비스를 제공받을…","fields":{"slug":"/3/"},"frontmatter":{"date":"September 06, 2025","title":"유저모드와 커널모드 전환, 시스템 콜의 동작 원리","tags":["운영체제"]},"rawMarkdownBody":"\n## 이중모드\n\n---\n\n운영체제는 자원을 충돌 없이 효율적으로 사용하기 위해 자원 관리의 진입점이 된다고 말했습니다.\n\n> 그럼 일반 응용프로그램은 어떻게 자원에 접근 할 수 있을까요?\n\n이에 대한 답은 **이중 모드** 입니다.\n\n<br>\n\n\n![img.png](dual_mode.png)\n\n<br>\n\n위 사진 처럼 **CPU**가 명령을 실행하는 방식을 **사용자 모드** 와 **커널 모드**로 나누어 사용하게 됩니다.\n\n<br>\n\n### 사용자 모드\n\n사용자 모드는 운영체제 서비스를 제공받을 수 없는 실행 모드입니다.\n</br> CPU가 해당 모드인 경우, 입출력 명령어와 같은 하드웨어 자원 접근 명령을 실행할 수 없습니다. 일반 프로그램은 기본적으로 사용자 모드로 실행됩니다.\n\n<br>\n\n### 커널 모드\n커널모드는 운영체제 서비스를 제공받을 수 있는 실행 모드로 커널 영역의 코드를 실행할 수 있습니다.\n</br> CPU가 커널 모드로 명령어를 실행하면 자원에 접근하는 명령어를 비롯한 모든 명령어를 실행할 수 있으며, 운영체제는 커널 모드로 실행됩니다.\n\n<br>\n\n요약 하자면 일반 응용프로그램은 평소에 **사용자 모드**를 통해서 실행 되다가 실제 운영체제의 코드를 실행하여야 하는 순간이 오면 **커널 모드**로 전환하여 실행하다가\n운영체제의 코드 실행 지점이 끝난다면 다시 **사용자 모드**로 전환되게 됩니다.\n\n이러한 방식으로 자원을 **운영 체제**로 하여금 독자적으로 관리할 수 있게 합니다.\n\n<br>\n\n> 사용자 모드에서 어떻게 커널모드로 전환할까?\n\n사용자 모드에서 커널모드로 전환하는 방식은 **시스템 콜**에 의해서 발생합니다.\n\n<br>\n\n![img.png](system_call.png)\n\n<br>\n\n그림처럼 사용자 모드로 실행되는 프로그램이 자원에 접근해야 할때 운영체제에 커널 모드로 요청을 보내게 되고 이것을 **시스템 콜**이라고 부르게 됩니다.\n\n**시스템 호출**은 **소프트 웨어 인터럽트**에 속합니다. 이러한 특징 때문에 **CPU**가 **시스템 호출**을 처리하는 순서가 **인터럽트 처리 순서**와 비슷합니다.\n\n**시스템 호출**이 발생하면 **지금까지의 작업을 백업** 하고, 커널 영역 내의 호출 하여야 하는 코드를 실행 한 뒤 다시 돌아와 기존 프로그램을 계속 실행합니다.\n\n<br>\n\n![img.png](system_call_method.png)\n\n<br>\n\n그림을 통해서 이해를 하게 되면,\n\n1. 응용 프로그램은 일반적인 작업을 수행중 운영체제 코드를 실행 하여야 하는 작업에 도달하게 됩니다.\n2. 그러면 응용프로그램은 운영체제에게 자원 접근에 대한 시스템 콜을 날리게 된다.\n3. 현재 작업을 백업하게 됩니다.\n4. 이후 응용프로그램은 운영체제의 코드를 실행합니다.\n5. 작업이 끝나면 다시 사용자 영역으로 돌아와 멈춰둔 작업을 진행합니다.\n\n이런 세부적인 순서를 진행하게 됩니다.\n\n### 출처\n[사진출처](https://hongong.hanbit.co.kr/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C%EB%9E%80-%EC%BB%A4%EB%84%90%EC%9D%98-%EA%B0%9C%EB%85%90-%EC%9D%91%EC%9A%A9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%8B%A4%ED%96%89%EC%9D%84-%EC%9C%84%ED%95%9C/)\n\n"},{"excerpt":"CPU 스케줄링 CPU 스케줄링은 CPU를 항상 바쁘게 동작시켜 자원을 낭비하지 않고 최적으로 활용할 수 있게 돕기도 하며,\n모든 프로세스로 하여금 CPU를 공정하게 할당할 수 있게 합니다. CPU 스케줄링이란 프로세스의 작업을 수행하기 위해 언제, 어떤 프로세스에 CPU를 할당할지 결정하는 작업을 말합니다.\n CPU 스케줄링 원칙 CPU는 스케줄링을 하…","fields":{"slug":"/2/"},"frontmatter":{"date":"September 05, 2025","title":"CPU 스케줄링, 시스템 자원 관리","tags":["운영체제"]},"rawMarkdownBody":"\n## CPU 스케줄링\n\n---\n\n**CPU 스케줄링**은 CPU를 항상 바쁘게 동작시켜 자원을 낭비하지 않고 최적으로 활용할 수 있게 돕기도 하며, \n<br>모든 프로세스로 하여금 CPU를 공정하게 할당할 수 있게 합니다.\n\nCPU 스케줄링이란 프로세스의 작업을 수행하기 위해 언제, 어떤 프로세스에 CPU를 할당할지 결정하는 작업을 말합니다.\n<br>\n\n### CPU 스케줄링 원칙\n\n---\n\nCPU는 스케줄링을 하면서 두가지 원칙을 중요시 하게 됩니다.\n<br>\n\n1. 공정함: 특정 프로세스 실행이 무한정 대기하지 않도록 기간을 보장합니다.\n2. 우선순위: 우선순위가 높은 작업에 우선권을 제공 합니다.\n\n<br>\n\n### CPU 스케줄링 평가 기준\n\n---\n\nCPU는 객관적인 스케줄링을 위해 아래와 같은 평가 기준을 사용합니다.\n\n<br>\n\n1. CPU 사용률 - CPU가 작업을 수행하는데 사용하는 시간의 비율\n2. 처리량 - 시스템이 단위 시간당 완료할 수 있는 작업의 양\n3. 응답 시간 - 시스템이 사용자의 요청에 반응하여 첫 번째 응답을 생성하기 시작하는데 걸리는 시간\n4. 대기 시간 - 프로세스가 실행되기 위해 CPU를 할당받아 준비 상태에서 대기하는 시간의 총합\n5. 처리 시간 - 특정 작업이 시작되었을 때부터 그 작업이 완전히 끝나는데 걸리는 시간의 총합\n\n"},{"excerpt":"앞서, 운영체제란 무엇인지 그리고 커널에 대해 간단하게 알아봤다.\n이제 커널이 어떻게 작동하는지 제대로 알아보자. 먼저 인터럽트(Interrupt)에 대해 알아야 한다.  컴퓨터는 위 사진처럼 주변 입출력 기기와 서로 통신하는데\n이 과정에서 서로 입출력 요청이 오가는데 이때 입출력 메커니즘들이 발생된다.\n이중 하나가 인터럽트이다. \n인터럽트는 중단시키다라…","fields":{"slug":"/2/"},"frontmatter":{"date":"September 04, 2025","title":"2. 커널의 작동 방식","tags":["운영체제"]},"rawMarkdownBody":"\n앞서, 운영체제란 무엇인지 그리고 커널에 대해 간단하게 알아봤다.\n이제 커널이 어떻게 작동하는지 제대로 알아보자.\n\n먼저 인터럽트(Interrupt)에 대해 알아야 한다.\n\n![img_3.png](img_3.png)\n\n컴퓨터는 위 사진처럼 주변 입출력 기기와 서로 통신하는데 \n이 과정에서 서로 입출력 요청이 오가는데 이때 입출력 메커니즘들이 발생된다.\n이중 하나가 인터럽트이다. \n\n![](img.png)\n인터럽트는 중단시키다라는 의미로 초인종과 같다고 할 수 있다.\n즉, 인터럽트가 발생하면 잠깐 멈추고 다시 실행된다.\n\n![](img_1.png)\n\n실제 발생하는 대부분의 인터럽트는 I/O 인터럽트이다.\n예를들면, 우리가 자바에서 print을 할 때 print라는 API를 파일이라는 인터페이스를 통해서 유저모드에서 커널 모드로 시스템 콜이 발생한다.\n유저모드 API에서 커널모드 구성요소에서 시스템 콜이 이어지고 디바이스 드라이버를 제어하기 시작하는데\n[이때 디바이스 드라이버가 인터럽트를 CPU에 요청한다. 이 행위를 IRQ라고 한다.](https://en.wikipedia.org/wiki/Interrupt_request#:~:text=In%20a%20computer,or%20mouse%20movements.)\n이러한 IRQ는 장치마다 다른 번호로 관리하게 된다.\n아무튼 출력기기에 출력이 되면, 다시 역순으로 디바이스(하드웨어)에서 디바이스 드라이버로,\n디바이스 드라이버에서 커널 모드로 해서 최종적으로 유저 모드로 다시 돌아오게 된다.\n\n![](img_4.png)\n이때, 이러한 행위 도중 wait을 걸면 블라킹(동기) 안걸면 논블라킹(비동기)으로 동작하게 된다.\n\n인터럽트에는 우선순위가 있고 외부 인터럽트인지 내부 인터럽트인지에 따라 우선순위가 달라진다.\n\n먼저, 외부 인터럽트로 내부 인터럽트보다 우선 시 된다.\n\n그 중에서도 우선 순위가 있는데, 다음과 같다.\n- 전원 이상 인터럽트: 말 그대로 정전 또는 파워 이상\n- 기계 착오 인터럽트: CPU의 기능적인 오류.\n- 외부 신호 인터럽트: 타이머 또는, 키보드 인터럽트 키(Ctrl + Alt + Delete). 외부장치로부터 인터럽트 요청이 있는 경우. I/O 인터럽트와 다른 개념이다.\n- 입출력 인터럽트: 입출력 장치가 데이터 전송을 요구하거나 전송이 끝나 다음 동작이 수행되어야 할 경우. 입출력 데이터에 이상이 있는 경우. 우리가 자주 다루게 될 인터럽트 부분이다.\n\n이제 내부 인터럽트인데, 사실 우리가 주로 다루게 될 것은 외부 인터럽트에 있어 내부 인터럽트는 뭐가 있는지만 대강 본다.\n\n- 명령어 잘못 인터럽트: 잘못된 명령어나 잘못된 데이터를 사용할 때 발생하며 Trap이라 부른다,\n- 프로그램 검사\n- 소프트웨어 인터럽트(=SVC, SuperVisor Call)\n\n인터럽트 동작 순서에 대해 다시 살펴보면 다음과 같은데,\n\n1. 인터럽트 요청\n2. 프로그램 실행 중단\n3. 현재 프로그램 상태 보존 -> PCB(Process Control Block), PC(Program Counter) 등\n4. 인터럽트 서비스 루틴 실행: 인터럽트 처리 코드\n5. 상태  복구\n6. 중단 프로그램 실행 재개\n\n![](img_2.png)\n\n이 과정에서 유저모드에서 커널모드로 넘어갈 떄 컨텍스트 스위칭이 되면서 오버헤드가 발생하는데 이로 인해 시스템 상 지연이 발생한다.\n하지만 고성능 어플리케이션을 할 때 이 지연은 꽤나 치명적일 것이다. \n그래서 위와 같이 DMA(Direct Memory Access)라는 기술을 사용하게 됐다.\n예를들어, DirectX라는 것이 있는데 이는 게임을 할 때 이러한 컨텍스트 스위칭 되는 부분을 건너뛰어 직접 드라이버까지 가는 방식이 있다.\n이렇듯 DirectX처럼 인터럽트 시 컨텍스트 스위칭으로 인한 오버헤드가 발생하면서 지연이 발생하는데 이걸 해소하는 것이 DMA인 것이다.\n정리하자면, [DMA는 RAM에 일정 부분을 예약해 불필요한 컨텍스트 스위칭을 스킵해 오버헤드 방지 및 지연을 획기적으로 줄이는 방식이다.](https://en.wikipedia.org/wiki/Direct_memory_access#:~:text=DMA%20(%20Direct%20Memory%20Access%20)%EB%8A%94%20%ED%8A%B9%EC%A0%95%20%ED%95%98%EB%93%9C%EC%9B%A8%EC%96%B4%20%ED%95%98%EC%9C%84%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%B4%20%EC%A4%91%EC%95%99%20%EC%B2%98%EB%A6%AC%20%EC%9E%A5%EC%B9%98%20(CPU)%20%EC%99%80%20%EB%8F%85%EB%A6%BD%EC%A0%81%EC%9C%BC%EB%A1%9C%20%EC%A3%BC%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EC%97%90%20%EC%95%A1%EC%84%B8%EC%8A%A4%ED%95%A0%20%EC%88%98%20%EC%9E%88%EB%8F%84%EB%A1%9D%20%ED%95%98%EB%8A%94%20%EC%BB%B4%ED%93%A8%ED%84%B0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%EA%B8%B0%EB%8A%A5%EC%9E%85%EB%8B%88%EB%8B%A4%20.)\n\n\n\n\n"},{"excerpt":"운영체제란 무엇일까? 운영체제는 컴퓨터 하드웨어와 소프트웨어를 관리하고, 사용자와 컴퓨터 사이 인터페이스 역할을 합니다. 대표적인 기능으로는 자원을 관리하고,\n 프로세스를 관리하는 등 여러가지 일을 수행합니다. 이러한 운영체제는 프로그램을 위한 프로그램으로서 작동하게 되며, 여러 프로그램을 충돌없이 효율적으로 사용하는 기능을 제공합니다. 운영체제의 역할 …","fields":{"slug":"/1/"},"frontmatter":{"date":"September 04, 2025","title":"운영체제의 역할과 커널의 기능","tags":["운영체제"]},"rawMarkdownBody":"\n## 운영체제란 무엇일까?\n\n---\n\n**운영체제**는 컴퓨터 하드웨어와 소프트웨어를 관리하고, 사용자와 컴퓨터 사이 인터페이스 역할을 합니다. 대표적인 기능으로는 **자원**을 **관리**하고, \n</br> 프로세스를 관리하는 등 여러가지 일을 수행합니다.\n\n이러한 **운영체제**는 프로그램을 위한 프로그램으로서 작동하게 되며, 여러 프로그램을 충돌없이 효율적으로 사용하는 기능을 제공합니다.\n\n\n## 운영체제의 역할\n\n---\n\n### 하드웨어 관리\n\n> 운영체제는 CPU, 메모리, 입출력 장치 등 컴퓨터 하드웨어 자원을 관리합니다.\n> </br> 여기서 말하는 **관리**란 자원의 충돌을 방지하고 사용자가 하드웨어를 **효율**적으로\n> 사용하도록 처리하는것을 의미하게 됩니다.\n\n<br>\n<br>\n\n### 프로세스 관리\n\n> 프로세스의 생성과 종료 그리고 CPU 스케줄링을 통해 프로세스의 실행 시간을 관리합니다. \n> </br> **멀티 태스킹**환경에서 프로세스 전환을 관리합니다.\n\n<br>\n<br>\n\n### 메모리 관리\n\n> 각 애플리케이션에 충분한 메모리 공간을 할당하는 기능을 합니다.\n> </br> 또한 가상 메모리를 통해 실제 메모리보다 큰 주소 공간을 제공합니다.\n\n## 커널이란 무엇일까?\n\n---\n\n**커널**이란 운영체제의 핵심 기능을 담당하며, 커널은 하드웨어와 소프트웨어 애플리케이션 간 통신을 관리합니다. 커널의 대표적인 기능으로는 \n</br> **프로세스 관리**, **메모리 관리**, **파일 시스템**, **입 출력 관리**의 역할을 수행하게 됩니다.\n\n위 설명 처럼 **운영체제**의 핵심기능을 **커널**이 많은 부분을 담당하기 때문에 이전에 설명한 운영체제의 기능이 **커널**의 기능이라고 생각하면 됩니다.\n\n\n## 커널이 자원을 관리하는 이유\n\n---\n\n> **커널**은 어떻게 충돌 없이 자원을 관리할까요?\n\n이 질문에 대한 대답은 자원을 관리하는 지점을 **커널**을 통한 단일 진입점으로 만들게 되면서 해결 하게 됩니다.\n<br>\n\n> 왜 자원을 **커널**을 통해서만 관리하게 설게 했을까요? \n\n**커널**이 자원을 혼자 관리해야 하는 이유를 예시를 들어서 설명하겠습니다.\n\n유치원 수업시간에 하나의 바구니에 **테이프**, **연필**, **지우개**와 같은 문구용품을 담아두고 선생님이 학생들에게 자율적으로 사용해도 된다고 하게 된다면 어떤일이 벌어질까요?\n\n처음에는 아이들이 각자 필요한 문구 용품을 사용하겠지만 얼마 가지 않아서 **연필**을 찾는 학생,\n</br> **테이프**를 가지고 누가먼저 쓸지 싸우는 학생,\n</br> 혹은 **지우개**를 망가뜨린 학생등 많은 사고가 있을 것입니다.\n\n이러한 문제가 벌어지는 이유는 공용 문구를 사용할때 **통제권**이 모두에게 있기 떄문입니다. 그렇다면 이를 해결하기 위해서\n모두에게 있는 **통제권**을 하나로 합쳐서 해결하면 되는 문제이고 이것이 자원을 사용하기 위해 **커널의 관리**를 받아야 하는 이유입니다.\n"},{"excerpt":"운영체제(OS, Operating System) 운영체제는 컴퓨터라는 기계 안에서 프로그램과 하드웨어 사이에서 문제없이 그리고 효율적으로 잘 돌아가도록 관리해주는 소프트웨어이다.  운영체제가 없으면 어떻게 될까? 꼭 필요할까? A computer is a machine that can be programmed to automatically carry ou…","fields":{"slug":"/hs/"},"frontmatter":{"date":"September 03, 2025","title":"1. 운영체제의 개념과 구조","tags":["운영체제"]},"rawMarkdownBody":"\n## 운영체제(OS, Operating System)\n\n[운영체제는 컴퓨터라는 기계 안에서 프로그램과 하드웨어 사이에서 문제없이 그리고 효율적으로 잘 돌아가도록 관리해주는 소프트웨어이다.](https://en.wikipedia.org/wiki/Operating_system#:~:text=An%20operating%20system%20(OS)%20is%20system%20software%20that%20manages%20computer%20hardware%20and%20software%20resources%2C%20and%20provides%20common%20services%20for%20computer%20programs.)\n\n![](img.png)\n\n운영체제가 없으면 어떻게 될까? 꼭 필요할까?\n\n> _A computer is a machine that can be programmed to automatically carry out sequences of arithmetic or logical operations_\n> (컴퓨터는 산술적 또는 논리적 연산(계산)의 순서를 자동으로 수행하도록 프로그래밍할 수 있는 기계이다).\n> [ - wikepedia](https://en.wikipedia.org/wiki/Computer#:~:text=A%20computer%20is%20a%20machine%20that%20can%20be%20programmed%20to%20automatically%20carry%20out%20sequences%20of%20arithmetic%20or%20logical%20operations%20(computation).)\n\n운영체제가 없다면 컴퓨터는 그저 하드웨어의 집합체에 불과하다. \n사용자는 프로그램을 실행하기 위해서 매번 하드웨어를 직접 제어해야 하며, 이렇게 하는 것은 매우 비효율적일거다. \n또한 직접 제어를 한다고 해도 하드웨어의 성능은 제한적이므로 이 환경에서 최대한의 성능을 끌어내기 위해 최적화라는 고통스러운 작업을 해야 할 것이다.\n이러한 상황을 상상해보면 \"배보다 배꼽이 더 크다\"라는 말이 떠오른다.\n\n실제로 운영체제라는 개념이 있기 전에는 사용자들이 하나의 작업을 위해 펀치카드를 소지하며 관리해야 했다.\n그리고 단순 하드웨어에 올려 실행하는 과정의 방식이기에 한 번에 하나의 프로그램만 실행할 수 있었고, 해당 프로그램이 끝나야 다른 프로그램을 수행할 수 있었다. \n지금처럼 복잡한 방식의 프로그램은 꿈도 꿀 수 없었을 것이다.\n\n이러한 문제를 해결하기 위해 운영체제가 나왔고, 다음과 같은 목적을 지닌다.\n\n- 사용자에게 컴퓨터의 프로그램을 쉽고 효율적으로 실행할 수 있는 환경을 제공한다.\n- 컴퓨터 시스템 하드웨어 및 소프트웨어 자원을 여러 사용자 간에 효율적 할당, 관리, 보호하는 것\n- 운영체제는 제어 프로그램으로서 사용자 프로그램의 오류나 잘못된 자원 사용을 감시하는 것과 입출력 장치 등의 자원에 대한 연산과 제어를 관리한다.\n\n운영체제은 위와 같은 목적을 위해 다양한 방식을 가지고 있다.\n\n### 일괄 처리 시스템 (Batch Operating System)\n\n사용자의 개입없이 비슷한 작업들을 모아서 순차적으로 처리하는 방식이다. \n한 작업이 끝나야 다음 작업이 실행되기 때문에 모든 작업이 완료될 때까지 기다릴 수 있는 환경에서 사용된다. \n주로 대용량 데이터를 처리하거나 시간이 많이 소요되는 작업에 활용되며, 사용자의 개입이 필요하지 않고 반복적인 작업을 일괄적으로 처리할 수 있다.\n\n### 다중 프로그래밍 시스템 (Multi Programming System)\n\n이 방식은 CPU을 최대한 사용하고 하는 방식으로,\n여러 응용프로그램을 메모리에 동시에 올라가 CPU가 쉬지 않고 여러 작업을 번갈아서 실행하며 항상 연산을 수행하는 상태로 활용하는 방식이다.\n하나의 프로그램을 실행하는 동안 다른 프로그램은 대기하거나 I/O 작업 등을 수행하며 메모리에 올라간 상태로 대기하게 된다.\n운영 체제는 이런 과정에서 CPU를 배분하는 작업 스케줄링과 CPU 스케줄링을 진행하며, \n이를 통해 시스템 자원을 효율적으로 활용하고 응용 프로그램들이 서로 영향을 주지 않으면서 병렬적으로 실행된다.\n\n### 시분할 시스템 (Time Sharing System)\n\n이 방식은 CPU에 대해 일정 시간을 할당 받아 짧은 간격으로 번갈아 실행하는 방식이다. \n다중 프로그래밍 시스템에서는 Context Switching(CPU 점유 권한 전환)이 I/O작업에서만 발생한다.\n이를 통해서만 스케줄링을 할 경우 하나의 프로세스가 아주 오래 CPU를 독점하고 있는 상태가 발생할 수 있다는 문제점이 있다.\n이를 해결하기 위한 것이 시분할 시스템으로, 다중 프로그래밍과 비슷하지만 모든 프로세스가 특정 시간만 CPU를 점유하고 다른 프로세스에 권한을 넘겨주는 방식으로\nContext Switching 기준 시간으로 시분할을 구현해서 RR(Round-Robin) 알고리즘으로 스케줄링을 한다.\n\n### 대화형 시스템(Interactive System)\n\n앞서 설명한 일괄 처리 시스템은 처리해야할 작업들을 한번에 정의하고 일괄적으로 처리하는 방식이었다.\n이러한 일괄 처리 시스템의 문제점은 처리가 이루어지는 중에 시스템의 상태를 확인하기가 힘들고, \n작업이 끝나 결과가 도출되기 전까지는 작업을 수정할 수도 없다는 문제점이 있었다.\n이를 보완하기위해 등장한 시스템이 대화형 시스템으로, \n작업 중에도 사용자가 데이터, 명령 또는 작업을 입력하면 컴퓨터가 즉각적으로 해당 입력에 응답하는 사용자와 컴퓨터 간의 상호작용을 통해 작동하는 방식이다.\n\n## 커널(Kernel)\n\n그럼 우리들의 컴퓨터 속 운영체제는 어떻게 이러한 기능을 수행하고 있을까?\n\n[운영체제의 이러한 핵심적인 부분을 담당하고 수행하는 것이 바로 커널이다.](https://en.wikipedia.org/wiki/Kernel_(operating_system)#:~:text=A%20kernel%20is%20a%20computer%20program%20at%20the%20core%20of%20a%20computer%27s%20operating%20system%20that%20always%20has%20complete%20control%20over%20everything%20in%20the%20system.) \n\n![](img_3.png)\n커널을 한글로 번역하면 핵심이다! 재밌지 아니한가? 아무튼 다시 돌아와서 커널은 어떻게 운영체제의 기능을 수행할까? \n\n[커널은 하드웨어를 인터페이스로 제공하여 여러 사용자 또는 여러 프로세스가 하드웨어 즉 리소스를 효율적으로 관리하며 작업을 수행할 수 있도록 해준다.](https://en.wikipedia.org/wiki/Kernel_(operating_system)#:~:text=The%20kernel%27s%20interface%20is%20a%20low%2Dlevel%20abstraction%20layer.%20When%20a%20process%20requests%20a%20service%20from%20the%20kernel%2C%20it%20must%20invoke%20a%20system%20call%2C%20usually%20through%20a%20wrapper%20function.)\n여기서 중요한 점은 커널은 사용자가 직접 제어할 수는 없다.\n그 이유는 보안상 유저 어플리케이션이 함부로 운영체제의 리소스를 건들지 못하게 하기 위해서다.\n그래서 커널에는 하드웨어에 접근이 허가된 커널모드와 그렇지 못한 유저모드로 분리가 되어있다.\n\n![](img_1.png)\n\n커널의 구조는 위 사진과 같은데, 간단한 흐름을 설명하자면 사용자가 유저모드인 어플리케이션을 실행하면서 발생하는 요청이 시스템 콜을 통해 커널 모드로 전환이 된다.\n애플리케이션은 커널모드로 전환되었다가 작업을 끝낸 후 응답을 반환하면서 다시 유저모드로 되돌아 가게 된다.\n여기서 시스템 콜은 뭐지 싶을텐데 [어플리케이션의 요청이 커널에 접근해 시스템에 요청하는 것](https://en.wikipedia.org/wiki/System_call#:~:text=In%20computing%2C%20a%20system%20call%20(syscall)%20is%20the%20programmatic%20way%20in%20which%20a%20computer%20program%20requests%20a%20service%20from%20the%20operating%20system%5Ba%5D%20on%20which%20it%20is%20executed.)으로 간단히 유저모드에서 커널모드로 전환하는 것이라고 생각하면 된다. \n\n![](img_4.png)\n\n이러한 방식을 통해 사용자의 프로세스가 직접적으로 운영체제의 리소스를 함부로 변경하지 못하게 보호해준다.\n\n"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}